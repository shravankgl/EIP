{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNST_CIFAR10_Shravan_B9_95.13.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "K70hAckqg0EA",
        "outputId": "a6cbc1af-9d8e-48bb-d799-34d4e1edf3b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wVIx_KIigxPV",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, Activation,GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler,ModelCheckpoint,ReduceLROnPlateau\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UNHw6luQg3gc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# # backend\n",
        "# import tensorflow as tf\n",
        "# from keras import backend as k\n",
        "\n",
        "# # Don't pre-allocate memory; allocate as-needed\n",
        "# config = tf.ConfigProto()\n",
        "# config.gpu_options.allow_growth = True\n",
        "\n",
        "# # Create a session with the above options specified.\n",
        "# k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dsO_yGxcg5D8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 250\n",
        "l = 16\n",
        "num_filter = 32\n",
        "growth_rate = 12\n",
        "compression = 0.5\n",
        "dropout_rate = 0.2\n",
        "weight_decay = 1e-4\n",
        "dilate_rate = 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mB7o3zu1g6eT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "90352c41-ebca-4a96-a9d6-a5e4d99eadfb"
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "x = np.vstack((x_train, x_test))\n",
        "for i in range(3):\n",
        "\t\tmean = np.mean(x[:, :, :, i])\n",
        "\t\tstd = np.std(x[:, :, :, i])\n",
        "\t\tx_train[:, :, :, i] = (x_train[:, :, :, i] - mean) / std\n",
        "\t\tx_test[:, :, :, i] = (x_test[:, :, :, i] - mean) / std"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 52s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ee-sge5Kg7vr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression, weight_decay, growth_rate\n",
        "\n",
        "    temp = input\n",
        "    \n",
        "    for _ in range(l):\n",
        "      \n",
        "        BatchNorm = BatchNormalization(gamma_regularizer=l2(weight_decay),beta_regularizer=l2(weight_decay))(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_1_1 = Conv2D(int(growth_rate*4), (1,1), use_bias=False ,padding='same',\n",
        "                              kernel_initializer='he_uniform',kernel_regularizer=l2(weight_decay))(relu)\n",
        "        \n",
        "        BatchNorm_1_1 = BatchNormalization(gamma_regularizer=l2(weight_decay),beta_regularizer=l2(weight_decay))(Conv2D_1_1)\n",
        "        relu_1_1 = Activation('relu')(BatchNorm_1_1)\n",
        "        Conv2D_3_3 = Conv2D(int(growth_rate), (3,3), use_bias=False ,padding='same', dilation_rate = dilate_rate,\n",
        "                              kernel_initializer='he_uniform',kernel_regularizer=l2(weight_decay))(relu_1_1)\n",
        "        \n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(rate=dropout_rate)(Conv2D_3_3)\n",
        "        \n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        num_filter += growth_rate\n",
        "        \n",
        "    return temp , num_filter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OOP6IPsGhBwb",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression, weight_decay\n",
        "    BatchNorm = BatchNormalization(gamma_regularizer=l2(weight_decay),beta_regularizer=l2(weight_decay))(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same',\n",
        "                              kernel_initializer='he_uniform',kernel_regularizer=l2(weight_decay))(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(rate=dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2),strides=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0RaKFpubhDIC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression, weight_decay\n",
        "    BatchNorm = BatchNormalization(gamma_regularizer=l2(weight_decay),beta_regularizer=l2(weight_decay))(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    #AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    #flat = Flatten()(AvgPooling)\n",
        "    #output = Dense(num_classes, activation='softmax')(flat)\n",
        "    GloAvgPooling = GlobalAveragePooling2D()(relu)\n",
        "    output = Dense(num_classes, activation='softmax',\n",
        "\t\tkernel_regularizer=l2(weight_decay),bias_regularizer=l2(weight_decay))(GloAvgPooling)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "anPCpQWhhGb7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "input = Input(shape=(img_height, img_width, channel))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same', dilation_rate = dilate_rate,\n",
        "\t\t\tkernel_initializer='he_uniform',kernel_regularizer=l2(weight_decay))(input)\n",
        "\n",
        "First_Block, num_filters = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filters, dropout_rate)\n",
        "\n",
        "Second_Block,num_filters = add_denseblock(First_Transition, num_filters, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filters, dropout_rate)\n",
        "\n",
        "# Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "# Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block,num_filters = add_denseblock(Second_Transition,  num_filters, dropout_rate)\n",
        "output = output_layer(Last_Block)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1kFh7pdxhNtT",
        "outputId": "b6ed9dbc-3fe0-4cc3-e7f4-2c3bdaa1f788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 14866
        }
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 32)   128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 48)   1536        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 48)   192         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 48)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 12)   5184        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 32, 32, 12)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 44)   0           conv2d[0][0]                     \n",
            "                                                                 dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 44)   176         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 44)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 48)   2112        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 48)   192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 48)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 12)   5184        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 12)   0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 56)   0           concatenate[0][0]                \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 56)   224         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 56)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 48)   2688        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 48)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 48)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 12)   5184        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 32, 12)   0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 68)   0           concatenate_1[0][0]              \n",
            "                                                                 dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 68)   272         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 68)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 48)   3264        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 48)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 48)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 12)   5184        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32, 32, 12)   0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 80)   0           concatenate_2[0][0]              \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 80)   320         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 80)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 48)   3840        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 48)   192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 48)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 12)   5184        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32, 32, 12)   0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 92)   0           concatenate_3[0][0]              \n",
            "                                                                 dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 92)   368         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 92)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 48)   4416        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 48)   192         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 48)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 12)   5184        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 32, 32, 12)   0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 104)  0           concatenate_4[0][0]              \n",
            "                                                                 dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 104)  416         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 104)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 48)   4992        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 48)   192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 12)   5184        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 32, 32, 12)   0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 116)  0           concatenate_5[0][0]              \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 116)  464         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 116)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 48)   5568        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 48)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 48)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 12)   5184        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 32, 32, 12)   0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 128)  0           concatenate_6[0][0]              \n",
            "                                                                 dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 128)  512         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 128)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 48)   6144        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 48)   192         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 32, 48)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 12)   5184        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 32, 32, 12)   0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 140)  0           concatenate_7[0][0]              \n",
            "                                                                 dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 32, 140)  560         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 32, 32, 140)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 48)   6720        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 48)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 48)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 12)   5184        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 32, 32, 12)   0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 152)  0           concatenate_8[0][0]              \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 152)  608         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 152)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 48)   7296        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 32, 32, 48)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 32, 48)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 32, 32, 12)   5184        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 32, 32, 12)   0           conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 164)  0           concatenate_9[0][0]              \n",
            "                                                                 dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 32, 32, 164)  656         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 32, 32, 164)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 32, 32, 48)   7872        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 32, 32, 48)   192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 32, 32, 48)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 32, 32, 12)   5184        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 32, 32, 12)   0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 176)  0           concatenate_10[0][0]             \n",
            "                                                                 dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 32, 32, 176)  704         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 32, 32, 176)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 32, 32, 48)   8448        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 32, 32, 48)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 32, 32, 48)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 32, 32, 12)   5184        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 32, 32, 12)   0           conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 32, 32, 188)  0           concatenate_11[0][0]             \n",
            "                                                                 dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 32, 32, 188)  752         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 32, 32, 188)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 32, 32, 48)   9024        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 32, 32, 48)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 32, 32, 48)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 32, 32, 12)   5184        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 32, 32, 12)   0           conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 32, 32, 200)  0           concatenate_12[0][0]             \n",
            "                                                                 dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 32, 32, 200)  800         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 32, 32, 200)  0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 32, 32, 48)   9600        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 32, 32, 48)   192         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 32, 32, 48)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 32, 32, 12)   5184        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 32, 32, 12)   0           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 32, 32, 212)  0           concatenate_13[0][0]             \n",
            "                                                                 dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 32, 32, 212)  848         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 32, 32, 212)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 32, 32, 48)   10176       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 32, 32, 48)   192         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 32, 32, 48)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 32, 32, 12)   5184        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 32, 32, 12)   0           conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 32, 32, 224)  0           concatenate_14[0][0]             \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 32, 32, 224)  896         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 32, 32, 224)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 32, 32, 112)  25088       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 32, 32, 112)  0           conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 112)  0           dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 16, 16, 112)  448         average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 16, 16, 112)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 16, 16, 48)   5376        activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 16, 16, 48)   192         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 16, 16, 48)   0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 16, 16, 12)   5184        activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 16, 16, 12)   0           conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 16, 16, 124)  0           average_pooling2d[0][0]          \n",
            "                                                                 dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 16, 16, 124)  496         concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 16, 16, 124)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 16, 16, 48)   5952        activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 16, 16, 48)   192         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 16, 16, 48)   0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 16, 16, 12)   5184        activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 16, 16, 12)   0           conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 16, 16, 136)  0           concatenate_16[0][0]             \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 16, 16, 136)  544         concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 16, 16, 136)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 16, 16, 48)   6528        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 16, 16, 48)   192         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 16, 16, 48)   0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 16, 16, 12)   5184        activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 16, 16, 12)   0           conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 16, 16, 148)  0           concatenate_17[0][0]             \n",
            "                                                                 dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 16, 16, 148)  592         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 16, 16, 148)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 16, 16, 48)   7104        activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 16, 16, 48)   192         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 16, 16, 48)   0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 16, 16, 12)   5184        activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 16, 16, 12)   0           conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 16, 16, 160)  0           concatenate_18[0][0]             \n",
            "                                                                 dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 16, 16, 160)  640         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 16, 16, 160)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 16, 16, 48)   7680        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 16, 16, 48)   192         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 16, 16, 48)   0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 16, 16, 12)   5184        activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 16, 16, 12)   0           conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 16, 16, 172)  0           concatenate_19[0][0]             \n",
            "                                                                 dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 16, 16, 172)  688         concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 16, 16, 172)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 16, 16, 48)   8256        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 16, 16, 48)   192         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 16, 16, 48)   0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 16, 16, 12)   5184        activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 16, 16, 12)   0           conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 16, 16, 184)  0           concatenate_20[0][0]             \n",
            "                                                                 dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 16, 16, 184)  736         concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 16, 16, 184)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 16, 16, 48)   8832        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 16, 16, 48)   192         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 16, 16, 48)   0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 16, 16, 12)   5184        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 16, 16, 12)   0           conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 16, 16, 196)  0           concatenate_21[0][0]             \n",
            "                                                                 dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 16, 16, 196)  784         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 16, 16, 196)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 16, 16, 48)   9408        activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 16, 16, 48)   192         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 16, 16, 48)   0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 16, 16, 12)   5184        activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 16, 16, 12)   0           conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 16, 16, 208)  0           concatenate_22[0][0]             \n",
            "                                                                 dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 16, 16, 208)  832         concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 16, 16, 208)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 16, 16, 48)   9984        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 16, 16, 48)   192         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 16, 16, 48)   0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 16, 16, 12)   5184        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 16, 16, 12)   0           conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 16, 16, 220)  0           concatenate_23[0][0]             \n",
            "                                                                 dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 16, 16, 220)  880         concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 16, 16, 220)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 16, 16, 48)   10560       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 16, 16, 48)   192         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 16, 16, 48)   0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 16, 16, 12)   5184        activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 16, 16, 12)   0           conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 16, 16, 232)  0           concatenate_24[0][0]             \n",
            "                                                                 dropout_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 16, 16, 232)  928         concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 16, 16, 232)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 16, 16, 48)   11136       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 16, 16, 48)   192         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 16, 16, 48)   0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 16, 16, 12)   5184        activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 16, 16, 12)   0           conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 16, 16, 244)  0           concatenate_25[0][0]             \n",
            "                                                                 dropout_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 16, 16, 244)  976         concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 16, 16, 244)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 16, 16, 48)   11712       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 16, 16, 48)   192         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 16, 16, 48)   0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 16, 16, 12)   5184        activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_28 (Dropout)            (None, 16, 16, 12)   0           conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 16, 16, 256)  0           concatenate_26[0][0]             \n",
            "                                                                 dropout_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 16, 16, 256)  1024        concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 16, 16, 256)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 16, 16, 48)   12288       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 16, 16, 48)   192         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 16, 16, 48)   0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 16, 16, 12)   5184        activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_29 (Dropout)            (None, 16, 16, 12)   0           conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 16, 16, 268)  0           concatenate_27[0][0]             \n",
            "                                                                 dropout_29[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 16, 16, 268)  1072        concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 16, 16, 268)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 16, 16, 48)   12864       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 16, 16, 48)   192         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 16, 16, 48)   0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 16, 16, 12)   5184        activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 16, 16, 12)   0           conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 16, 16, 280)  0           concatenate_28[0][0]             \n",
            "                                                                 dropout_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 16, 16, 280)  1120        concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 16, 16, 280)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 16, 16, 48)   13440       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 16, 16, 48)   192         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 16, 16, 48)   0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 16, 16, 12)   5184        activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_31 (Dropout)            (None, 16, 16, 12)   0           conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 16, 16, 292)  0           concatenate_29[0][0]             \n",
            "                                                                 dropout_31[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 16, 16, 292)  1168        concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 16, 16, 292)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 16, 16, 48)   14016       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 16, 16, 48)   192         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 16, 16, 48)   0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 16, 16, 12)   5184        activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_32 (Dropout)            (None, 16, 16, 12)   0           conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 16, 16, 304)  0           concatenate_30[0][0]             \n",
            "                                                                 dropout_32[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 16, 16, 304)  1216        concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 16, 16, 304)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 16, 16, 208)  63232       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_33 (Dropout)            (None, 16, 16, 208)  0           conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 8, 8, 208)    0           dropout_33[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 8, 8, 208)    832         average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 8, 8, 208)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 8, 8, 48)     9984        activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 8, 8, 48)     192         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 8, 8, 48)     0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 8, 8, 12)     5184        activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_34 (Dropout)            (None, 8, 8, 12)     0           conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 8, 8, 220)    0           average_pooling2d_1[0][0]        \n",
            "                                                                 dropout_34[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 8, 8, 220)    880         concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 8, 8, 220)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 8, 8, 48)     10560       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 8, 8, 48)     192         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 8, 8, 48)     0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 8, 8, 12)     5184        activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_35 (Dropout)            (None, 8, 8, 12)     0           conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 8, 8, 232)    0           concatenate_32[0][0]             \n",
            "                                                                 dropout_35[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 8, 8, 232)    928         concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 8, 8, 232)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 48)     11136       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 48)     192         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 48)     0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 8, 8, 12)     5184        activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_36 (Dropout)            (None, 8, 8, 12)     0           conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 8, 8, 244)    0           concatenate_33[0][0]             \n",
            "                                                                 dropout_36[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 8, 8, 244)    976         concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 8, 8, 244)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 8, 8, 48)     11712       activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 8, 8, 48)     192         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 8, 8, 48)     0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 8, 8, 12)     5184        activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 8, 8, 12)     0           conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 8, 8, 256)    0           concatenate_34[0][0]             \n",
            "                                                                 dropout_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 8, 8, 256)    1024        concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 8, 8, 256)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 48)     12288       activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 8, 8, 48)     192         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 48)     0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 12)     5184        activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_38 (Dropout)            (None, 8, 8, 12)     0           conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 8, 8, 268)    0           concatenate_35[0][0]             \n",
            "                                                                 dropout_38[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 268)    1072        concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 268)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 48)     12864       activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 48)     192         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 48)     0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 12)     5184        activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_39 (Dropout)            (None, 8, 8, 12)     0           conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 8, 8, 280)    0           concatenate_36[0][0]             \n",
            "                                                                 dropout_39[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 280)    1120        concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 280)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 48)     13440       activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 48)     192         conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 48)     0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 12)     5184        activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_40 (Dropout)            (None, 8, 8, 12)     0           conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 8, 8, 292)    0           concatenate_37[0][0]             \n",
            "                                                                 dropout_40[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 292)    1168        concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 292)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 48)     14016       activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 48)     192         conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 48)     0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 12)     5184        activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_41 (Dropout)            (None, 8, 8, 12)     0           conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 8, 8, 304)    0           concatenate_38[0][0]             \n",
            "                                                                 dropout_41[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 304)    1216        concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 304)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 48)     14592       activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 48)     192         conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 48)     0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 12)     5184        activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_42 (Dropout)            (None, 8, 8, 12)     0           conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 8, 8, 316)    0           concatenate_39[0][0]             \n",
            "                                                                 dropout_42[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 316)    1264        concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 316)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 48)     15168       activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 48)     192         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 48)     0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 12)     5184        activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_43 (Dropout)            (None, 8, 8, 12)     0           conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 8, 8, 328)    0           concatenate_40[0][0]             \n",
            "                                                                 dropout_43[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 328)    1312        concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 328)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 48)     15744       activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 48)     192         conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 48)     0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 12)     5184        activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_44 (Dropout)            (None, 8, 8, 12)     0           conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 8, 8, 340)    0           concatenate_41[0][0]             \n",
            "                                                                 dropout_44[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 340)    1360        concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 340)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 48)     16320       activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 48)     192         conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 48)     0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 12)     5184        activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_45 (Dropout)            (None, 8, 8, 12)     0           conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 8, 8, 352)    0           concatenate_42[0][0]             \n",
            "                                                                 dropout_45[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 352)    1408        concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 352)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 48)     16896       activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 48)     192         conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 48)     0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 12)     5184        activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_46 (Dropout)            (None, 8, 8, 12)     0           conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 8, 8, 364)    0           concatenate_43[0][0]             \n",
            "                                                                 dropout_46[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 364)    1456        concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 364)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 48)     17472       activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 48)     192         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 48)     0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 8, 8, 12)     5184        activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_47 (Dropout)            (None, 8, 8, 12)     0           conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 8, 8, 376)    0           concatenate_44[0][0]             \n",
            "                                                                 dropout_47[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 8, 8, 376)    1504        concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 8, 8, 376)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 8, 8, 48)     18048       activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 8, 8, 48)     192         conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 8, 8, 48)     0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 8, 8, 12)     5184        activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_48 (Dropout)            (None, 8, 8, 12)     0           conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 8, 8, 388)    0           concatenate_45[0][0]             \n",
            "                                                                 dropout_48[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 8, 8, 388)    1552        concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 8, 8, 388)    0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 8, 8, 48)     18624       activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 8, 8, 48)     192         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 8, 8, 48)     0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 8, 8, 12)     5184        activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_49 (Dropout)            (None, 8, 8, 12)     0           conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 8, 8, 400)    0           concatenate_46[0][0]             \n",
            "                                                                 dropout_49[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 8, 8, 400)    1600        concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 8, 8, 400)    0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 400)          0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           4010        global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 872,458\n",
            "Trainable params: 846,090\n",
            "Non-trainable params: 26,368\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IeZElodLEG45",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "\t\t\tfeaturewise_center=False,  # set input mean to 0 over the dataset\n",
        "\t\t\tsamplewise_center=False,  # set each sample mean to 0\n",
        "\t\t\tfeaturewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "\t\t\tsamplewise_std_normalization=False,  # divide each input by its std\n",
        "\t\t\tzca_whitening=False,  # apply ZCA whitening\n",
        "\t\t\trotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "\t\t\twidth_shift_range=0.16,  # randomly shift images horizontally (fraction of total width)\n",
        "\t\t\theight_shift_range=0.16,  # randomly shift images vertically (fraction of total height)\n",
        "\t\t\thorizontal_flip=True,  # randomly flip images\n",
        "\t\t\tvertical_flip=False) # randomly flip images\n",
        "       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l0CI3oZKvqyQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def step_decay(epoch):\n",
        "\tinitial_lrate = 0.1\n",
        "\tlrate = 0.1\n",
        "\tif epoch >= 125 and epoch < 187:\n",
        "\t\tlrate = initial_lrate / 10\n",
        "\tif epoch >= 187 :\n",
        "\t\tlrate = initial_lrate / 100\n",
        "\t\n",
        "\treturn float(lrate)\n",
        "lrschedular = LearningRateScheduler(step_decay)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "b4XOsW3ahSkL",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer=Adam(),\n",
        "#               metrics=['accuracy'])\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(lr=0.1,momentum=0.9,nesterov=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "w5oLYwEMqK79",
        "outputId": "0d602050-3fa2-4b7d-b2d4-2cdaf9ad0db8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "cell_type": "code",
      "source": [
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(model,\n",
        "                                              strategy = tf.contrib.tpu.TPUDistributionStrategy(\n",
        "                                                  tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://'+os.environ['COLAB_TPU_ADDR'])\n",
        "                                              )\n",
        "                                             )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (b'grpc://10.42.64.154:8470') for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 11119241873497611646)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 4897110816159873529)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 18060014126107472569)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 12044001936908973557)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 14980512190903242416)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 15962530922079010424)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 15449957814665183519)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 1918361334192475174)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 11026850350379046354)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6469989983092986736)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 9263364650442660003)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 15073145030976500248)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.10000000149011612, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': True}\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.10000000149011612, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': True}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "crhGk7kEhXAz",
        "outputId": "36ce3fcb-db9a-40e7-ca27-6aa4242501bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9050
        }
      },
      "cell_type": "code",
      "source": [
        "# tpu_model.fit(x_train, y_train,\n",
        "#                     batch_size=batch_size,\n",
        "#                     epochs=50,\n",
        "#                     verbose=1,\n",
        "#                     validation_data=(x_test, y_test))\n",
        "\n",
        "tpu_model.fit_generator(datagen.flow(x_train, y_train,\n",
        "\t\t\t\t\t\t\t\t\t batch_size=64),\n",
        "\t\t\t\t\t\tsteps_per_epoch=782,epochs=250,verbose=1,callbacks=[lrschedular])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(8,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(8, 32, 32, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(8, 10), dtype=tf.float32, name='dense_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.10000000149011612, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': True}\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.SGD object at 0x7f342bf24be0> []\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 87.47735667228699 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "INFO:tensorflow:CPU -> TPU lr: 0.10000000149011612 {0.1}\n",
            "INFO:tensorflow:CPU -> TPU momentum: 0.8999999761581421 {0.9}\n",
            "INFO:tensorflow:CPU -> TPU decay: 0.0 {0.0}\n",
            "WARNING:tensorflow:Cannot update non-variable config: nesterov\n",
            "332/782 [===========>..................] - ETA: 5:27 - loss: 3.6708 - acc: 0.3297INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(2,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(2, 32, 32, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(2, 10), dtype=tf.float32, name='dense_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.SGD object at 0x7f342bf24be0> [<tf.Variable 'tpu_139862206264712/SGD/iterations:0' shape=() dtype=int64>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412f82a20>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412f82ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412f82eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412f88dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412eebf28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412f14128>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412edd940>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412e47ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412deff28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412db4eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412da1fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412ceff28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412d13c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412c7fe10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412c48eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412bedda0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412bdcf60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412b26ac8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412b4af28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412ab7d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412a81d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412a28c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412a11d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34129dbcf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412982da0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34128f27f0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34128bcd68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34128e0c88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341284a5f8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412814eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34127641d0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412727f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34126f0f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34126bcb00>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412626be0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412650978>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412618f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412583fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341252ad30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34124f4e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412463c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341242af60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412451e80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34123bcda0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412386e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412329d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341231ac50>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34122e0f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412287eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34121f3cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34121befd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412166f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412152c88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3412119e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34120c0d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341202f7b8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411ff9fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341201de48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411f8c550>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411f56e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411ef7470>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411e63c50>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411e2efd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411df8a90>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411d68d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411d894e0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411d54e80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411cc3fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411c68cc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411c2fda0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411c20ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411b69c50>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411b8df28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411afad30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411ac2dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411a6def0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411a55cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411a1feb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34119c3e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411933d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34118fcd30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411921fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341188ce10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411856dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34117fccc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341176cf28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411734f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411756dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34116c9c50>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411693d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411637400>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411621c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341156cf60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411533278>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34114a4748>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34114c7ba8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411491e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34113fff60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411422160>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341136ffd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341135bef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34112fff28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34112c8eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411235fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411200c88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34111a5a20>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411192e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341115aef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411101dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3411071c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341103ceb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341105df60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410fcbda0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410f95d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410f38c50>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410ea9d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410e71d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410e95dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410e07c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410dcefd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410d74cc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410d5eb70>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410ca8ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410c71208>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410c61a90>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410c03fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410bceb38>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410b3cef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410ae30f0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410aab908>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410a9ae80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410a3ed68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410a07e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410977f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410940c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34108e4eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34108cedd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341089be80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341083ed68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34107adef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410777d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341079bef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410707cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34106d3cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410679b70>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34105e6cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34105aecc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34105d3d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34105427b8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341050cd30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34104b1e80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341049c588>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34103eae80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341040bb38>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341037bf60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410343f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341030dac8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341027fd68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34102a1d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34101eaeb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34101d6fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341017bcc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f3410144dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34100b6f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341007cef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f34100a1e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f341000ed68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340ffd9e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340ff7ecf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340fee9d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340feb6ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340fed7e80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340fe47fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340fe0ed68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340fdb9f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340fd24e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340fceee10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340fd11cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340fc81f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340fc4af98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340fbece10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340fbde550>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340fb28d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340fb49cc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340fab8c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340fa83f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340fa4c2b0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f9b9780>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f9de4a8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f928e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f913f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f8b9198>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f8824a8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f7f1f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f816f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f7e1ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f74ccf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f718da0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f6bceb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f629cc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f5f1f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f619e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f588d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f552ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f4f5f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f4e2da0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f42ada0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f451c88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f3bff28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f389fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f32ada0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f2bf7b8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f64fc50>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f289cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f1f6be0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f1bfef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f188240>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f0f9e80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f11ecf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f066dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340f052f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340eff7160>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340efc4fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340ef2eeb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340ef55d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340ef1ee80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340ee8ac88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340ee58f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340edfac18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340ed64e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340ed2feb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340ed55da0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340ecc6f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340ec8dac8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340ec32f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340ec1dd68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340eb66d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340eb90c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340eafcd30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340eac4cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340ea6ada0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340ea5b7f0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e9a3d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e9c9c88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e9335f8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e8feeb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e8cd1d0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e892f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e85af98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e7a3b00>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e78fbe0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e73a978>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e701f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e66efd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e692d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e65ce10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e5cac18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e594f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e53ae80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e4a6da0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e471e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e494d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e403c50>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e3cbf28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e371eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e35dcf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e2a5fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e2cef98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e23ac88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e203e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e1a8d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e1957b8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e161fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e106e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e075550>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e03fe48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340e060470>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340dfccc50>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340df99fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340df61a90>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340decdd30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340de764e0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340de40e80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340ddaffd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340ddd0cc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340dd9ada0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340dd0aef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340dcd3c50>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340dc78f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340dc62d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340dbaedd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340dbd5ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340db41cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340db08eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340daafe48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340da9ed30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340d9e7d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340da0bfd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f340d9d3eb8>]\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 96.17935752868652 secs\n",
            "782/782 [==============================] - 405s 518ms/step - loss: 3.3302 - acc: 0.4135\n",
            "Epoch 2/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 2.5242 - acc: 0.5759\n",
            "Epoch 3/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 2.0671 - acc: 0.6353\n",
            "Epoch 4/250\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 1.7561 - acc: 0.6805\n",
            "Epoch 5/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 1.5257 - acc: 0.7143\n",
            "Epoch 6/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 1.3696 - acc: 0.7326\n",
            "Epoch 7/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 1.2597 - acc: 0.7471\n",
            "Epoch 8/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 1.1775 - acc: 0.7587\n",
            "Epoch 9/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 1.1230 - acc: 0.7681\n",
            "Epoch 10/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 1.0889 - acc: 0.7703\n",
            "Epoch 11/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 1.0599 - acc: 0.7780\n",
            "Epoch 12/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 1.0340 - acc: 0.7832\n",
            "Epoch 13/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 1.0156 - acc: 0.7871\n",
            "Epoch 14/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 1.0105 - acc: 0.7881\n",
            "Epoch 15/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9936 - acc: 0.7940\n",
            "Epoch 16/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.9928 - acc: 0.7929\n",
            "Epoch 17/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.9838 - acc: 0.7957\n",
            "Epoch 18/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9744 - acc: 0.7993\n",
            "Epoch 19/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9727 - acc: 0.8002\n",
            "Epoch 20/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9602 - acc: 0.8051\n",
            "Epoch 21/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9586 - acc: 0.8058\n",
            "Epoch 22/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.9554 - acc: 0.8061\n",
            "Epoch 23/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.9519 - acc: 0.8068\n",
            "Epoch 24/250\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 0.9488 - acc: 0.8092\n",
            "Epoch 25/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9452 - acc: 0.8122\n",
            "Epoch 26/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9428 - acc: 0.8126\n",
            "Epoch 27/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9377 - acc: 0.8154\n",
            "Epoch 28/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9419 - acc: 0.8127\n",
            "Epoch 29/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9299 - acc: 0.8155\n",
            "Epoch 30/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9380 - acc: 0.8141\n",
            "Epoch 31/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.9347 - acc: 0.8157\n",
            "Epoch 32/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9268 - acc: 0.8209\n",
            "Epoch 33/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9290 - acc: 0.8183\n",
            "Epoch 34/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9234 - acc: 0.8189\n",
            "Epoch 35/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9259 - acc: 0.8196\n",
            "Epoch 36/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9231 - acc: 0.8216\n",
            "Epoch 37/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.9257 - acc: 0.8218\n",
            "Epoch 38/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9259 - acc: 0.8199\n",
            "Epoch 39/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9247 - acc: 0.8200\n",
            "Epoch 40/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.9264 - acc: 0.8221\n",
            "Epoch 41/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9212 - acc: 0.8234\n",
            "Epoch 42/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9175 - acc: 0.8246\n",
            "Epoch 43/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9212 - acc: 0.8246\n",
            "Epoch 44/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.9185 - acc: 0.8235\n",
            "Epoch 45/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9153 - acc: 0.8244\n",
            "Epoch 46/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.9161 - acc: 0.8236\n",
            "Epoch 47/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9182 - acc: 0.8258\n",
            "Epoch 48/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9184 - acc: 0.8232\n",
            "Epoch 49/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9112 - acc: 0.8279\n",
            "Epoch 50/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9178 - acc: 0.8236\n",
            "Epoch 51/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9155 - acc: 0.8242\n",
            "Epoch 52/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9135 - acc: 0.8264\n",
            "Epoch 53/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9113 - acc: 0.8288\n",
            "Epoch 54/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9154 - acc: 0.8260\n",
            "Epoch 55/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9107 - acc: 0.8277\n",
            "Epoch 56/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9099 - acc: 0.8269\n",
            "Epoch 57/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9134 - acc: 0.8251\n",
            "Epoch 58/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9068 - acc: 0.8283\n",
            "Epoch 59/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9129 - acc: 0.8287\n",
            "Epoch 60/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.9042 - acc: 0.8310\n",
            "Epoch 61/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9091 - acc: 0.8296\n",
            "Epoch 62/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9076 - acc: 0.8274\n",
            "Epoch 63/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9099 - acc: 0.8298\n",
            "Epoch 64/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9104 - acc: 0.8287\n",
            "Epoch 65/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9046 - acc: 0.8289\n",
            "Epoch 66/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.9021 - acc: 0.8311\n",
            "Epoch 67/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9058 - acc: 0.8316\n",
            "Epoch 68/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.9030 - acc: 0.8308\n",
            "Epoch 69/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.9068 - acc: 0.8301\n",
            "Epoch 70/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.9069 - acc: 0.8281\n",
            "Epoch 71/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.9070 - acc: 0.8300\n",
            "Epoch 72/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8971 - acc: 0.8345\n",
            "Epoch 73/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9044 - acc: 0.8285\n",
            "Epoch 74/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.8982 - acc: 0.8321\n",
            "Epoch 75/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.8982 - acc: 0.8319\n",
            "Epoch 76/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8960 - acc: 0.8333\n",
            "Epoch 77/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.9014 - acc: 0.8321\n",
            "Epoch 78/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8983 - acc: 0.8320\n",
            "Epoch 79/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.8954 - acc: 0.8337\n",
            "Epoch 80/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.9009 - acc: 0.8318\n",
            "Epoch 81/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.8982 - acc: 0.8318\n",
            "Epoch 82/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9025 - acc: 0.8318\n",
            "Epoch 83/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.9026 - acc: 0.8315\n",
            "Epoch 84/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9013 - acc: 0.8325\n",
            "Epoch 85/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8976 - acc: 0.8340\n",
            "Epoch 86/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.8953 - acc: 0.8343\n",
            "Epoch 87/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8962 - acc: 0.8330\n",
            "Epoch 88/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8979 - acc: 0.8332\n",
            "Epoch 89/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9005 - acc: 0.8336\n",
            "Epoch 90/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9002 - acc: 0.8322\n",
            "Epoch 91/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8907 - acc: 0.8358\n",
            "Epoch 92/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.8976 - acc: 0.8332\n",
            "Epoch 93/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.8952 - acc: 0.8330\n",
            "Epoch 94/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8963 - acc: 0.8311\n",
            "Epoch 95/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8959 - acc: 0.8322\n",
            "Epoch 96/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8954 - acc: 0.8348\n",
            "Epoch 97/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8966 - acc: 0.8354\n",
            "Epoch 98/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.8916 - acc: 0.8355\n",
            "Epoch 99/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8913 - acc: 0.8345\n",
            "Epoch 100/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8914 - acc: 0.8349\n",
            "Epoch 101/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.8969 - acc: 0.8328\n",
            "Epoch 102/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8974 - acc: 0.8347\n",
            "Epoch 103/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8984 - acc: 0.8341\n",
            "Epoch 104/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.8960 - acc: 0.8337\n",
            "Epoch 105/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.8894 - acc: 0.8357\n",
            "Epoch 106/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8948 - acc: 0.8356\n",
            "Epoch 107/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8952 - acc: 0.8339\n",
            "Epoch 108/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.8905 - acc: 0.8369\n",
            "Epoch 109/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.8948 - acc: 0.8346\n",
            "Epoch 110/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8959 - acc: 0.8336\n",
            "Epoch 111/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8958 - acc: 0.8352\n",
            "Epoch 112/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8936 - acc: 0.8361\n",
            "Epoch 113/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8901 - acc: 0.8364\n",
            "Epoch 114/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8894 - acc: 0.8383\n",
            "Epoch 115/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8898 - acc: 0.8359\n",
            "Epoch 116/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8933 - acc: 0.8358\n",
            "Epoch 117/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8911 - acc: 0.8364\n",
            "Epoch 118/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8859 - acc: 0.8376\n",
            "Epoch 119/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8876 - acc: 0.8361\n",
            "Epoch 120/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8918 - acc: 0.8355\n",
            "Epoch 121/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.8974 - acc: 0.8316\n",
            "Epoch 122/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8861 - acc: 0.8383\n",
            "Epoch 123/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.8874 - acc: 0.8360\n",
            "Epoch 124/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8875 - acc: 0.8359\n",
            "Epoch 125/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8908 - acc: 0.8363\n",
            "Epoch 126/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.7526 - acc: 0.8821\n",
            "Epoch 127/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.6855 - acc: 0.9016\n",
            "Epoch 128/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.6599 - acc: 0.9061\n",
            "Epoch 129/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.6374 - acc: 0.9114\n",
            "Epoch 130/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.6192 - acc: 0.9141\n",
            "Epoch 131/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.6019 - acc: 0.9181\n",
            "Epoch 132/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.5924 - acc: 0.9175\n",
            "Epoch 133/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.5759 - acc: 0.9204\n",
            "Epoch 134/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.5644 - acc: 0.9224\n",
            "Epoch 135/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.5565 - acc: 0.9225\n",
            "Epoch 136/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.5389 - acc: 0.9255\n",
            "Epoch 137/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.5383 - acc: 0.9234\n",
            "Epoch 138/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.5263 - acc: 0.9248\n",
            "Epoch 139/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.5216 - acc: 0.9253\n",
            "Epoch 140/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.5109 - acc: 0.9275\n",
            "Epoch 141/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.5003 - acc: 0.9282\n",
            "Epoch 142/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4918 - acc: 0.9299\n",
            "Epoch 143/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4879 - acc: 0.9290\n",
            "Epoch 144/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.4845 - acc: 0.9286\n",
            "Epoch 145/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4756 - acc: 0.9300\n",
            "Epoch 146/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4684 - acc: 0.9304\n",
            "Epoch 147/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4659 - acc: 0.9293\n",
            "Epoch 148/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4609 - acc: 0.9296\n",
            "Epoch 149/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4579 - acc: 0.9305\n",
            "Epoch 150/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.4537 - acc: 0.9307\n",
            "Epoch 151/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.4456 - acc: 0.9315\n",
            "Epoch 152/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.4413 - acc: 0.9310\n",
            "Epoch 153/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.4406 - acc: 0.9304\n",
            "Epoch 154/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4382 - acc: 0.9312\n",
            "Epoch 155/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4340 - acc: 0.9313\n",
            "Epoch 156/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4320 - acc: 0.9321\n",
            "Epoch 157/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4305 - acc: 0.9305\n",
            "Epoch 158/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4259 - acc: 0.9311\n",
            "Epoch 159/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4230 - acc: 0.9326\n",
            "Epoch 160/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4180 - acc: 0.9325\n",
            "Epoch 161/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.4206 - acc: 0.9319\n",
            "Epoch 162/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4189 - acc: 0.9318\n",
            "Epoch 163/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4167 - acc: 0.9314\n",
            "Epoch 164/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4138 - acc: 0.9320\n",
            "Epoch 165/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4115 - acc: 0.9318\n",
            "Epoch 166/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.4075 - acc: 0.9318\n",
            "Epoch 167/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4064 - acc: 0.9321\n",
            "Epoch 168/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4106 - acc: 0.9317\n",
            "Epoch 169/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4078 - acc: 0.9317\n",
            "Epoch 170/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4134 - acc: 0.9293\n",
            "Epoch 171/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4059 - acc: 0.9318\n",
            "Epoch 172/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4073 - acc: 0.9303\n",
            "Epoch 173/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.4040 - acc: 0.9333\n",
            "Epoch 174/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.4041 - acc: 0.9313\n",
            "Epoch 175/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.4053 - acc: 0.9301\n",
            "Epoch 176/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.4021 - acc: 0.9327\n",
            "Epoch 177/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3987 - acc: 0.9332\n",
            "Epoch 178/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.3981 - acc: 0.9327\n",
            "Epoch 179/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.4001 - acc: 0.9316\n",
            "Epoch 180/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.4031 - acc: 0.9301\n",
            "Epoch 181/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.3979 - acc: 0.9320\n",
            "Epoch 182/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4000 - acc: 0.9307\n",
            "Epoch 183/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4003 - acc: 0.9310\n",
            "Epoch 184/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.3918 - acc: 0.9346\n",
            "Epoch 185/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3970 - acc: 0.9314\n",
            "Epoch 186/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3950 - acc: 0.9324\n",
            "Epoch 187/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.3970 - acc: 0.9304\n",
            "Epoch 188/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3565 - acc: 0.9475\n",
            "Epoch 189/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.3330 - acc: 0.9546\n",
            "Epoch 190/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.3238 - acc: 0.9582\n",
            "Epoch 191/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3197 - acc: 0.9590\n",
            "Epoch 192/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.3138 - acc: 0.9607\n",
            "Epoch 193/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3108 - acc: 0.9622\n",
            "Epoch 194/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3079 - acc: 0.9621\n",
            "Epoch 195/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3063 - acc: 0.9617\n",
            "Epoch 196/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3050 - acc: 0.9624\n",
            "Epoch 197/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3011 - acc: 0.9643\n",
            "Epoch 198/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3001 - acc: 0.9654\n",
            "Epoch 199/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2980 - acc: 0.9651\n",
            "Epoch 200/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2990 - acc: 0.9644\n",
            "Epoch 201/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2949 - acc: 0.9660\n",
            "Epoch 202/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2946 - acc: 0.9655\n",
            "Epoch 203/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2918 - acc: 0.9673\n",
            "Epoch 204/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2924 - acc: 0.9656\n",
            "Epoch 205/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.2866 - acc: 0.9680\n",
            "Epoch 206/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2901 - acc: 0.9658\n",
            "Epoch 207/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2879 - acc: 0.9674\n",
            "Epoch 208/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2853 - acc: 0.9687\n",
            "Epoch 209/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.2813 - acc: 0.9689\n",
            "Epoch 210/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.2850 - acc: 0.9679\n",
            "Epoch 211/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.2798 - acc: 0.9691\n",
            "Epoch 212/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2803 - acc: 0.9697\n",
            "Epoch 213/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.2791 - acc: 0.9690\n",
            "Epoch 214/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2784 - acc: 0.9705\n",
            "Epoch 215/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2763 - acc: 0.9700\n",
            "Epoch 216/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.2773 - acc: 0.9693\n",
            "Epoch 217/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.2753 - acc: 0.9705\n",
            "Epoch 218/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2756 - acc: 0.9702\n",
            "Epoch 219/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.2765 - acc: 0.9700\n",
            "Epoch 220/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.2728 - acc: 0.9707\n",
            "Epoch 221/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2720 - acc: 0.9705\n",
            "Epoch 222/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2705 - acc: 0.9708\n",
            "Epoch 223/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2697 - acc: 0.9710\n",
            "Epoch 224/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2678 - acc: 0.9709\n",
            "Epoch 225/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.2687 - acc: 0.9708\n",
            "Epoch 226/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.2683 - acc: 0.9722\n",
            "Epoch 227/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2655 - acc: 0.9723\n",
            "Epoch 228/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.2640 - acc: 0.9727\n",
            "Epoch 229/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2610 - acc: 0.9742\n",
            "Epoch 230/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.2654 - acc: 0.9720\n",
            "Epoch 231/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2643 - acc: 0.9711\n",
            "Epoch 232/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2601 - acc: 0.9734\n",
            "Epoch 233/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2619 - acc: 0.9729\n",
            "Epoch 234/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2597 - acc: 0.9723\n",
            "Epoch 235/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2588 - acc: 0.9735\n",
            "Epoch 236/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2595 - acc: 0.9733\n",
            "Epoch 237/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2561 - acc: 0.9743\n",
            "Epoch 238/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2558 - acc: 0.9744\n",
            "Epoch 239/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2543 - acc: 0.9748\n",
            "Epoch 240/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2564 - acc: 0.9722\n",
            "Epoch 241/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2520 - acc: 0.9750\n",
            "Epoch 242/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2534 - acc: 0.9740\n",
            "Epoch 243/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2521 - acc: 0.9747\n",
            "Epoch 244/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.2517 - acc: 0.9750\n",
            "Epoch 245/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2541 - acc: 0.9735\n",
            "Epoch 246/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2544 - acc: 0.9734\n",
            "Epoch 247/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2500 - acc: 0.9754\n",
            "Epoch 248/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.2484 - acc: 0.9750\n",
            "Epoch 249/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2478 - acc: 0.9751\n",
            "Epoch 250/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.2458 - acc: 0.9759\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3441dfc748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZcWydmIVhZGr",
        "outputId": "ed983059-cb41-47ae-d3e6-ca150a98ebed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = tpu_model.evaluate(x_test, y_test, verbose=1)\n",
        "print(score)\n",
        "print('Test loss: %.3f ' % (score[0]))\n",
        "print('Test accuracy: %.3f ' % (score[1]*100))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 11s 1ms/step\n",
            "[0.3576820640087128, 0.9513]\n",
            "Test loss: 0.358 \n",
            "Test accuracy: 95.130 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UE3lF6EH1r_L",
        "outputId": "c4e38a58-f138-4457-be98-30c06ab3a8f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "tpu_model.save_weights(\"DNST_weights_Shravan_B9.h5\")\n",
        "tpu_model.save(\"DNST_model_Shravan_B9.hdf5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU momentum: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU nesterov: True\n",
            "WARNING:tensorflow:Cannot update non-variable config: nesterov\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU momentum: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU nesterov: True\n",
            "WARNING:tensorflow:Cannot update non-variable config: nesterov\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Og56VCRh5j8V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VmSIqsez3C-o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Link for \n",
        "Weights:  https://drive.google.com/open?id=14lLLPW7OZtJ0flWSkMkoghfqxfzKxjGH \n",
        "Model:  https://drive.google.com/open?id=1RC4TCM72gSdoVNfjA63a_hcUG8IBpSZB\n",
        "\n",
        "\n",
        "# References\n",
        "1. Original Densenet Paper: https://arxiv.org/pdf/1608.06993\n",
        "2. https://medium.com/intuitionmachine/notes-on-the-implementation-densenet-in-tensorflow-beeda9dd1504\n",
        "3. https://forums.fast.ai/t/training-a-model-from-scratch-cifar-10/7897\n",
        "4. https://towardsdatascience.com/densenet-2810936aeebb\n",
        "5. https://towardsdatascience.com/normalized-direction-preserving-adam-switching-from-adam-to-sgd-and-nesterov-momentum-adam-with-460be5ddf686\n",
        "\n",
        "\n",
        "# Densenet implementations\n",
        "1. Original Densenet Implementation: https://github.com/liuzhuang13/DenseNet\n",
        "2. Fast.ai: http://files.fast.ai/part2/lesson13/densenet-keras.ipynb\n",
        "3. Github Users\n",
        "\ta. https://github.com/titu1994/DenseNet\n",
        "\tb. https://github.com/flyyufelix/DenseNet-Keras \n",
        "\n",
        "# LR Callbacks\n",
        "1. Cyclic Learning Rate: https://github.com/bckenstler/CLR\n",
        "2. SGDR: https://gist.github.com/t2kasa/490610116ddb0f3b664458d0e086e643\n",
        "3. SWATS: https://arxiv.org/pdf/1712.07628 (Implementation not found)\n",
        "\thttps://github.com/kweonwooj/papers/issues/76\n",
        "\thttps://www.groundai.com/project/improving-generalization-performance-by-switching-from-adam-to-sgd/\n",
        "\t"
      ]
    }
  ]
}