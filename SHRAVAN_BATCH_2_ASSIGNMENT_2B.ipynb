{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Program for backpropogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#np.set_printoptions(precision=2)\n",
    "\n",
    "sigmoid = lambda x : 1/(1+np.exp(-x))\n",
    "derivatives_sigmoid = lambda x : x*(1-x)\n",
    "\n",
    "def display_matrix(input,dc=2):#dc=decimal count\n",
    "    r,c = input.shape\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            input[i, j] = round(input[i, j], dc)\n",
    "    return input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 0:** Read input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 0\n",
    "x = np.array([[1, 0, 1, 0], [1, 0, 1, 1], [0, 1, 0, 1]])\n",
    "y = np.array([[1], [1], [0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Initialize weights and biases with random values (There are methods to initialize weights and biases but for now initialize with random values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wh\n",
      "[[0.62 0.21 0.07]\n",
      " [0.99 0.68 0.26]\n",
      " [0.82 0.42 0.85]\n",
      " [0.06 0.23 0.5 ]]\n",
      "\n",
      "bh\n",
      "[[0.92 0.78 0.44]]\n",
      "\n",
      "wout\n",
      "[[0.48]\n",
      " [0.01]\n",
      " [0.3 ]]\n",
      "\n",
      "bout\n",
      "[[0.74]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 1\n",
    "wh = np.random.rand(4,3)\n",
    "bh = np.random.rand(1,3)\n",
    "wout = np.random.rand(3,1)\n",
    "bout = np.random.rand(1,1)\n",
    "\n",
    "#For cross verification with demo\n",
    "#wh = np.array([[.42,.88,.55],[.1,.73,.68],[.6,.18,.47],[.92,.11,.52]])\n",
    "#bh = np.array([[.46,.72,.08]])\n",
    "#wout = np.array([[.3],[.25],[.23]])\n",
    "#bout = np.array([[.69]])\n",
    "\n",
    "print(\"wh\")\n",
    "print(display_matrix(wh))\n",
    "print()\n",
    "print(\"bh\")\n",
    "print(display_matrix(bh))\n",
    "print()\n",
    "print(\"wout\")\n",
    "print(display_matrix(wout))\n",
    "print()\n",
    "print(\"bout\")\n",
    "print(display_matrix(bout))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Calculate hidden layer input:\n",
    "`hidden_layer_input = matrix_dot_product(X,wh) + bh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_layer_input\n",
      "[[2.36 1.41 1.36]\n",
      " [2.42 1.64 1.86]\n",
      " [1.97 1.69 1.2 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 2\n",
    "hidden_layer_input = np.dot(x, wh) + bh\n",
    "print(\"hidden_layer_input\")\n",
    "print(display_matrix(hidden_layer_input))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Perform non-linear transformation on hidden linear input\n",
    "`hiddenlayer_activations = sigmoid(hidden_layer_input)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_layer_activations\n",
      "[[0.91 0.8  0.8 ]\n",
      " [0.92 0.84 0.87]\n",
      " [0.88 0.84 0.77]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 3\n",
    "hidden_layer_activations = sigmoid(hidden_layer_input)\n",
    "print(\"hidden_layer_activations\")\n",
    "print(display_matrix(hidden_layer_activations))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Perform linear and non-linear transformation of hidden layer activation at output layer\n",
    "`output_layer_input = matrix_dot_product (hiddenlayer_activations * wout ) + bout` \n",
    "`output = sigmoid(output_layer_input)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output\n",
      "[[0.81]\n",
      " [0.81]\n",
      " [0.8 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 4\n",
    "output_layer_input = np.dot(hidden_layer_activations,wout)+bout\n",
    "output = sigmoid(output_layer_input)\n",
    "print(\"output\")\n",
    "print(display_matrix(output))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:** Calculate gradient of Error(E) at output layer\n",
    "`E = y-output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\n",
      "[[ 0.19]\n",
      " [ 0.19]\n",
      " [-0.8 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 5\n",
    "error = y - output\n",
    "print(\"E\")\n",
    "print(display_matrix(error))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6:** Compute slope at output and hidden layer\n",
    "`Slope_output_layer= derivatives_sigmoid(output) Slope_hidden_layer = derivatives_sigmoid(hiddenlayer_activations)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope_output_layer\n",
      "[[0.15]\n",
      " [0.15]\n",
      " [0.16]]\n",
      "\n",
      "slope_hidden_layer\n",
      "[[0.08 0.16 0.16]\n",
      " [0.07 0.13 0.11]\n",
      " [0.11 0.13 0.18]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 6\n",
    "slope_output_layer = derivatives_sigmoid(output)\n",
    "slope_hidden_layer = derivatives_sigmoid(hidden_layer_activations)\n",
    "\n",
    "print(\"slope_output_layer\")\n",
    "print(display_matrix(slope_output_layer))\n",
    "print()\n",
    "print(\"slope_hidden_layer\")\n",
    "print(display_matrix(slope_hidden_layer))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7:** Compute delta at output layer\n",
    "`d_output = E * slope_output_layer*lr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta_output\n",
      "[[ 0.03]\n",
      " [ 0.03]\n",
      " [-0.13]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 7\n",
    "learning_rate = 1\n",
    "delta_output = error * slope_output_layer * learning_rate\n",
    "print(\"delta_output\")\n",
    "print(display_matrix(delta_output))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 8:** Calculate Error at hidden layer\n",
    "`Error_at_hidden_layer = matrix_dot_product(d_output, wout.Transpose)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error_at_hidden_layer\n",
      "[[ 0.014  0.     0.009]\n",
      " [ 0.014  0.     0.009]\n",
      " [-0.062 -0.001 -0.039]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 8\n",
    "error_at_hidden_layer = np.dot(delta_output, np.transpose(wout))\n",
    "print(\"Error_at_hidden_layer\")\n",
    "print(display_matrix(error_at_hidden_layer,3))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 9:** Compute delta at hidden layer\n",
    "`d_hiddenlayer = Error_at_hidden_layer * slope_hidden_layer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta_hidden_layer\n",
      "[[ 0.001  0.     0.001]\n",
      " [ 0.001  0.     0.001]\n",
      " [-0.007 -0.    -0.007]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 9\n",
    "delta_hidden_layer = error_at_hidden_layer * slope_hidden_layer\n",
    "print(\"delta_hidden_layer\")\n",
    "print(display_matrix(delta_hidden_layer,3))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 10:** Update weight at both output and hidden layer\n",
    "`wout = wout + matrix_dot_product (hiddenlayer_activations.Transpose, d_output) * learning_rate`\n",
    "`wh = wh+ matrix_dot_product (X.Transpose,d_hiddenlayer) * learning_rate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wout\n",
      "[[0.47]\n",
      " [0.  ]\n",
      " [0.3 ]]\n",
      "\n",
      "wh\n",
      "[[0.62 0.21 0.07]\n",
      " [0.99 0.68 0.26]\n",
      " [0.82 0.42 0.85]\n",
      " [0.06 0.23 0.5 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 10\n",
    "learning_rate = 0.1\n",
    "wout= wout + np.dot(np.transpose(hidden_layer_activations), delta_output) * learning_rate\n",
    "print(\"wout\")\n",
    "print(display_matrix(wout))\n",
    "print()\n",
    "\n",
    "wh = wh + np.dot(np.transpose(x), delta_hidden_layer) * learning_rate\n",
    "print(\"wh\")\n",
    "print(display_matrix(wh))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 11:** Update biases at both output and hidden layer\n",
    "`bh = bh + sum(d_hiddenlayer, axis=0) * learning_rate`\n",
    "`bout = bout + sum(d_output, axis=0)*learning_rate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bh\n",
      "[[0.92 0.78 0.44]]\n",
      "\n",
      "bout\n",
      "[[0.73]]\n"
     ]
    }
   ],
   "source": [
    "#Step 11\n",
    "bh = bh + np.sum(delta_hidden_layer, axis=0) * learning_rate\n",
    "bout= bout + np.sum(delta_output, axis=0) * learning_rate\n",
    "print(\"bh\")\n",
    "print(display_matrix(bh))\n",
    "print()\n",
    "print(\"bout\")\n",
    "print(display_matrix(bout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
