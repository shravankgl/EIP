{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNST_CIFAR10_Shravan_B9_95.3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "wVIx_KIigxPV",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, Activation,GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler,ModelCheckpoint,ReduceLROnPlateau\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dsO_yGxcg5D8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 250\n",
        "l = 16\n",
        "num_filter = 32\n",
        "growth_rate = 12\n",
        "compression = 0.5\n",
        "dropout_rate = 0.0\n",
        "weight_decay = 1e-4\n",
        "dilate_rate = 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mB7o3zu1g6eT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "#x_train /= 255.\n",
        "#x_test /= 255.\n",
        "\n",
        "# x = np.vstack((x_train, x_test))\n",
        "for i in range(3):\n",
        "\t\tmean = np.mean(x_train[:, :, :, i])\n",
        "\t\tstd = np.std(x_train[:, :, :, i])\n",
        "\t\tx_train[:, :, :, i] = (x_train[:, :, :, i] - mean) / std\n",
        "\t\tx_test[:, :, :, i] = (x_test[:, :, :, i] - mean) / std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ee-sge5Kg7vr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression, weight_decay, growth_rate\n",
        "\n",
        "    temp = input\n",
        "    \n",
        "    for _ in range(l):\n",
        "      \n",
        "        BatchNorm = BatchNormalization(gamma_regularizer=l2(weight_decay),beta_regularizer=l2(weight_decay))(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_1_1 = Conv2D(int(growth_rate*4), (1,1), use_bias=False ,padding='same',\n",
        "                              kernel_initializer='he_uniform',kernel_regularizer=l2(weight_decay))(relu)\n",
        "        \n",
        "        BatchNorm_1_1 = BatchNormalization(gamma_regularizer=l2(weight_decay),beta_regularizer=l2(weight_decay))(Conv2D_1_1)\n",
        "        relu_1_1 = Activation('relu')(BatchNorm_1_1)\n",
        "        Conv2D_3_3 = Conv2D(int(growth_rate), (3,3), use_bias=False ,padding='same', dilation_rate = dilate_rate,\n",
        "                              kernel_initializer='he_uniform',kernel_regularizer=l2(weight_decay))(relu_1_1)\n",
        "        \n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(rate=dropout_rate)(Conv2D_3_3)\n",
        "        \n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        num_filter += growth_rate\n",
        "        \n",
        "    return temp , num_filter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OOP6IPsGhBwb",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression, weight_decay\n",
        "    BatchNorm = BatchNormalization(gamma_regularizer=l2(weight_decay),beta_regularizer=l2(weight_decay))(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same',\n",
        "                              kernel_initializer='he_uniform',kernel_regularizer=l2(weight_decay))(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(rate=dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2),strides=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0RaKFpubhDIC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression, weight_decay\n",
        "    BatchNorm = BatchNormalization(gamma_regularizer=l2(weight_decay),beta_regularizer=l2(weight_decay))(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    #AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    #flat = Flatten()(AvgPooling)\n",
        "    #output = Dense(num_classes, activation='softmax')(flat)\n",
        "    GloAvgPooling = GlobalAveragePooling2D()(relu)\n",
        "    output = Dense(num_classes, activation='softmax',\n",
        "\t\tkernel_regularizer=l2(weight_decay),bias_regularizer=l2(weight_decay))(GloAvgPooling)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "anPCpQWhhGb7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "input = Input(shape=(img_height, img_width, channel))\n",
        "#input = Input(shape=(8, 8, channel))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same', dilation_rate = dilate_rate,\n",
        "\t\t\tkernel_initializer='he_uniform',kernel_regularizer=l2(weight_decay))(input)\n",
        "\n",
        "First_Block, num_filters = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filters, dropout_rate)\n",
        "Second_Block,num_filters = add_denseblock(First_Transition, num_filters, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filters, dropout_rate)\n",
        "# Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "# Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block,num_filters = add_denseblock(Second_Transition,  num_filters, dropout_rate)\n",
        "output = output_layer(Last_Block)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1kFh7pdxhNtT",
        "outputId": "35de68bd-5ee7-4d44-def7-01ac518f4152",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13129
        }
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 32)   128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 48)   1536        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 48)   192         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 48)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 12)   5184        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 44)   0           conv2d[0][0]                     \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 44)   176         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 44)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 48)   2112        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 48)   192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 48)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 12)   5184        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 56)   0           concatenate[0][0]                \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 56)   224         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 56)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 48)   2688        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 48)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 48)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 12)   5184        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 68)   0           concatenate_1[0][0]              \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 68)   272         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 68)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 48)   3264        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 48)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 48)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 12)   5184        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 80)   0           concatenate_2[0][0]              \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 80)   320         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 80)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 48)   3840        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 48)   192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 48)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 12)   5184        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 92)   0           concatenate_3[0][0]              \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 92)   368         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 92)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 48)   4416        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 48)   192         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 48)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 12)   5184        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 104)  0           concatenate_4[0][0]              \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 104)  416         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 104)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 48)   4992        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 48)   192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 12)   5184        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 116)  0           concatenate_5[0][0]              \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 116)  464         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 116)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 48)   5568        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 48)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 48)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 12)   5184        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 128)  0           concatenate_6[0][0]              \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 128)  512         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 128)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 48)   6144        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 48)   192         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 32, 48)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 12)   5184        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 140)  0           concatenate_7[0][0]              \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 32, 140)  560         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 32, 32, 140)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 48)   6720        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 48)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 48)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 12)   5184        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 152)  0           concatenate_8[0][0]              \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 152)  608         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 152)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 48)   7296        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 32, 32, 48)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 32, 48)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 32, 32, 12)   5184        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 164)  0           concatenate_9[0][0]              \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 32, 32, 164)  656         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 32, 32, 164)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 32, 32, 48)   7872        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 32, 32, 48)   192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 32, 32, 48)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 32, 32, 12)   5184        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 176)  0           concatenate_10[0][0]             \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 32, 32, 176)  704         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 32, 32, 176)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 32, 32, 48)   8448        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 32, 32, 48)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 32, 32, 48)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 32, 32, 12)   5184        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 32, 32, 188)  0           concatenate_11[0][0]             \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 32, 32, 188)  752         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 32, 32, 188)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 32, 32, 48)   9024        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 32, 32, 48)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 32, 32, 48)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 32, 32, 12)   5184        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 32, 32, 200)  0           concatenate_12[0][0]             \n",
            "                                                                 conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 32, 32, 200)  800         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 32, 32, 200)  0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 32, 32, 48)   9600        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 32, 32, 48)   192         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 32, 32, 48)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 32, 32, 12)   5184        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 32, 32, 212)  0           concatenate_13[0][0]             \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 32, 32, 212)  848         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 32, 32, 212)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 32, 32, 48)   10176       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 32, 32, 48)   192         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 32, 32, 48)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 32, 32, 12)   5184        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 32, 32, 224)  0           concatenate_14[0][0]             \n",
            "                                                                 conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 32, 32, 224)  896         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 32, 32, 224)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 32, 32, 112)  25088       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 112)  0           conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 16, 16, 112)  448         average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 16, 16, 112)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 16, 16, 48)   5376        activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 16, 16, 48)   192         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 16, 16, 48)   0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 16, 16, 12)   5184        activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 16, 16, 124)  0           average_pooling2d[0][0]          \n",
            "                                                                 conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 16, 16, 124)  496         concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 16, 16, 124)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 16, 16, 48)   5952        activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 16, 16, 48)   192         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 16, 16, 48)   0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 16, 16, 12)   5184        activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 16, 16, 136)  0           concatenate_16[0][0]             \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 16, 16, 136)  544         concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 16, 16, 136)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 16, 16, 48)   6528        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 16, 16, 48)   192         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 16, 16, 48)   0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 16, 16, 12)   5184        activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 16, 16, 148)  0           concatenate_17[0][0]             \n",
            "                                                                 conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 16, 16, 148)  592         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 16, 16, 148)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 16, 16, 48)   7104        activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 16, 16, 48)   192         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 16, 16, 48)   0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 16, 16, 12)   5184        activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 16, 16, 160)  0           concatenate_18[0][0]             \n",
            "                                                                 conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 16, 16, 160)  640         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 16, 16, 160)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 16, 16, 48)   7680        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 16, 16, 48)   192         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 16, 16, 48)   0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 16, 16, 12)   5184        activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 16, 16, 172)  0           concatenate_19[0][0]             \n",
            "                                                                 conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 16, 16, 172)  688         concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 16, 16, 172)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 16, 16, 48)   8256        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 16, 16, 48)   192         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 16, 16, 48)   0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 16, 16, 12)   5184        activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 16, 16, 184)  0           concatenate_20[0][0]             \n",
            "                                                                 conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 16, 16, 184)  736         concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 16, 16, 184)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 16, 16, 48)   8832        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 16, 16, 48)   192         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 16, 16, 48)   0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 16, 16, 12)   5184        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 16, 16, 196)  0           concatenate_21[0][0]             \n",
            "                                                                 conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 16, 16, 196)  784         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 16, 16, 196)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 16, 16, 48)   9408        activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 16, 16, 48)   192         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 16, 16, 48)   0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 16, 16, 12)   5184        activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 16, 16, 208)  0           concatenate_22[0][0]             \n",
            "                                                                 conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 16, 16, 208)  832         concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 16, 16, 208)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 16, 16, 48)   9984        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 16, 16, 48)   192         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 16, 16, 48)   0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 16, 16, 12)   5184        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 16, 16, 220)  0           concatenate_23[0][0]             \n",
            "                                                                 conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 16, 16, 220)  880         concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 16, 16, 220)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 16, 16, 48)   10560       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 16, 16, 48)   192         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 16, 16, 48)   0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 16, 16, 12)   5184        activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 16, 16, 232)  0           concatenate_24[0][0]             \n",
            "                                                                 conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 16, 16, 232)  928         concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 16, 16, 232)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 16, 16, 48)   11136       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 16, 16, 48)   192         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 16, 16, 48)   0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 16, 16, 12)   5184        activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 16, 16, 244)  0           concatenate_25[0][0]             \n",
            "                                                                 conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 16, 16, 244)  976         concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 16, 16, 244)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 16, 16, 48)   11712       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 16, 16, 48)   192         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 16, 16, 48)   0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 16, 16, 12)   5184        activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 16, 16, 256)  0           concatenate_26[0][0]             \n",
            "                                                                 conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 16, 16, 256)  1024        concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 16, 16, 256)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 16, 16, 48)   12288       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 16, 16, 48)   192         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 16, 16, 48)   0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 16, 16, 12)   5184        activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 16, 16, 268)  0           concatenate_27[0][0]             \n",
            "                                                                 conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 16, 16, 268)  1072        concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 16, 16, 268)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 16, 16, 48)   12864       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 16, 16, 48)   192         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 16, 16, 48)   0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 16, 16, 12)   5184        activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 16, 16, 280)  0           concatenate_28[0][0]             \n",
            "                                                                 conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 16, 16, 280)  1120        concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 16, 16, 280)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 16, 16, 48)   13440       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 16, 16, 48)   192         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 16, 16, 48)   0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 16, 16, 12)   5184        activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 16, 16, 292)  0           concatenate_29[0][0]             \n",
            "                                                                 conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 16, 16, 292)  1168        concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 16, 16, 292)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 16, 16, 48)   14016       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 16, 16, 48)   192         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 16, 16, 48)   0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 16, 16, 12)   5184        activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 16, 16, 304)  0           concatenate_30[0][0]             \n",
            "                                                                 conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 16, 16, 304)  1216        concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 16, 16, 304)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 16, 16, 208)  63232       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 8, 8, 208)    0           conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 8, 8, 208)    832         average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 8, 8, 208)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 8, 8, 48)     9984        activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 8, 8, 48)     192         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 8, 8, 48)     0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 8, 8, 12)     5184        activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 8, 8, 220)    0           average_pooling2d_1[0][0]        \n",
            "                                                                 conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 8, 8, 220)    880         concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 8, 8, 220)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 8, 8, 48)     10560       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 8, 8, 48)     192         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 8, 8, 48)     0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 8, 8, 12)     5184        activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 8, 8, 232)    0           concatenate_32[0][0]             \n",
            "                                                                 conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 8, 8, 232)    928         concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 8, 8, 232)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 48)     11136       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 48)     192         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 48)     0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 8, 8, 12)     5184        activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 8, 8, 244)    0           concatenate_33[0][0]             \n",
            "                                                                 conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 8, 8, 244)    976         concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 8, 8, 244)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 8, 8, 48)     11712       activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 8, 8, 48)     192         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 8, 8, 48)     0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 8, 8, 12)     5184        activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 8, 8, 256)    0           concatenate_34[0][0]             \n",
            "                                                                 conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 8, 8, 256)    1024        concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 8, 8, 256)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 48)     12288       activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 8, 8, 48)     192         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 48)     0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 12)     5184        activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 8, 8, 268)    0           concatenate_35[0][0]             \n",
            "                                                                 conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 268)    1072        concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 268)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 48)     12864       activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 48)     192         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 48)     0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 12)     5184        activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 8, 8, 280)    0           concatenate_36[0][0]             \n",
            "                                                                 conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 280)    1120        concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 280)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 48)     13440       activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 48)     192         conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 48)     0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 12)     5184        activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 8, 8, 292)    0           concatenate_37[0][0]             \n",
            "                                                                 conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 292)    1168        concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 292)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 48)     14016       activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 48)     192         conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 48)     0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 12)     5184        activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 8, 8, 304)    0           concatenate_38[0][0]             \n",
            "                                                                 conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 304)    1216        concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 304)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 48)     14592       activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 48)     192         conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 48)     0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 12)     5184        activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 8, 8, 316)    0           concatenate_39[0][0]             \n",
            "                                                                 conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 316)    1264        concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 316)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 48)     15168       activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 48)     192         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 48)     0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 12)     5184        activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 8, 8, 328)    0           concatenate_40[0][0]             \n",
            "                                                                 conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 328)    1312        concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 328)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 48)     15744       activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 48)     192         conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 48)     0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 12)     5184        activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 8, 8, 340)    0           concatenate_41[0][0]             \n",
            "                                                                 conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 340)    1360        concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 340)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 48)     16320       activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 48)     192         conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 48)     0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 12)     5184        activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 8, 8, 352)    0           concatenate_42[0][0]             \n",
            "                                                                 conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 352)    1408        concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 352)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 48)     16896       activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 48)     192         conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 48)     0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 12)     5184        activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 8, 8, 364)    0           concatenate_43[0][0]             \n",
            "                                                                 conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 364)    1456        concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 364)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 48)     17472       activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 48)     192         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 48)     0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 8, 8, 12)     5184        activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 8, 8, 376)    0           concatenate_44[0][0]             \n",
            "                                                                 conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 8, 8, 376)    1504        concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 8, 8, 376)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 8, 8, 48)     18048       activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 8, 8, 48)     192         conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 8, 8, 48)     0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 8, 8, 12)     5184        activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 8, 8, 388)    0           concatenate_45[0][0]             \n",
            "                                                                 conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 8, 8, 388)    1552        concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 8, 8, 388)    0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 8, 8, 48)     18624       activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 8, 8, 48)     192         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 8, 8, 48)     0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 8, 8, 12)     5184        activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 8, 8, 400)    0           concatenate_46[0][0]             \n",
            "                                                                 conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 8, 8, 400)    1600        concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 8, 8, 400)    0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 400)          0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           4010        global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 872,458\n",
            "Trainable params: 846,090\n",
            "Non-trainable params: 26,368\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IeZElodLEG45",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "\t\t\tfeaturewise_center=False,  # set input mean to 0 over the dataset\n",
        "\t\t\tsamplewise_center=False,  # set each sample mean to 0\n",
        "\t\t\tfeaturewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "\t\t\tsamplewise_std_normalization=False,  # divide each input by its std\n",
        "\t\t\tzca_whitening=False,  # apply ZCA whitening\n",
        "\t\t\trotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "\t\t\twidth_shift_range=0.16,  # randomly shift images horizontally (fraction of total width)\n",
        "\t\t\theight_shift_range=0.16,  # randomly shift images vertically (fraction of total height)\n",
        "\t\t\thorizontal_flip=True,  # randomly flip images\n",
        "\t\t\tvertical_flip=False, # randomly flip images\n",
        "      zoom_range=0.2) #Zoom Images\n",
        "       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "b4XOsW3ahSkL",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer=Adam(),\n",
        "#               metrics=['accuracy'])\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(lr=0.1,momentum=0.9,nesterov=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l0CI3oZKvqyQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def step_decay(epoch):\n",
        "\tinitial_lrate = 0.1\n",
        "\tlrate = 0.1\n",
        "\tif epoch >= 125 and epoch < 187:\n",
        "\t\tlrate = initial_lrate / 10\n",
        "\tif epoch >= 187 and epoch < 225:\n",
        "\t\tlrate = initial_lrate / 100\n",
        "\tif epoch >= 225:\n",
        "\t\tlrate = initial_lrate / 1000 \n",
        "\n",
        "# def step_decay(epoch):\n",
        "# \tinitial_lrate = 0.1\n",
        "# \tlrate = 0.1\n",
        "# \tif epoch >= 25 and epoch < 38:\n",
        "# \t\tlrate = initial_lrate / 10\n",
        "# \tif epoch >= 38:\n",
        "# \t\tlrate = initial_lrate / 100\n",
        "\t\n",
        "\t\n",
        "\treturn float(lrate)\n",
        "lrschedular = LearningRateScheduler(step_decay)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "w5oLYwEMqK79",
        "outputId": "9a4b75b3-1c4e-4ffd-be17-ca009ef605ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "cell_type": "code",
      "source": [
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(model,\n",
        "                                              strategy = tf.contrib.tpu.TPUDistributionStrategy(\n",
        "                                                  tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://'+os.environ['COLAB_TPU_ADDR'])\n",
        "                                              )\n",
        "                                             )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (b'grpc://10.120.214.10:8470') for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 7107417351258393734)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 17802880795952711629)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 4528232773096294253)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 16008770196790935247)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 2346588609011345544)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 3317873281457116570)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 8714162427300281773)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 7990632562408134009)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 15235284395436947342)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 9129609137501064991)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 5507154223421941376)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 5021030493959748764)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.10000000149011612, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': True}\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.10000000149011612, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': True}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "crhGk7kEhXAz",
        "outputId": "391f9a63-2ab8-4c69-a7c2-35eb0e4575b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9276
        }
      },
      "cell_type": "code",
      "source": [
        "# tpu_model.fit(x_train, y_train,\n",
        "#                     batch_size=batch_size,\n",
        "#                     epochs=50,\n",
        "#                     verbose=1,\n",
        "#                     validation_data=(x_test, y_test))\n",
        "\n",
        "tpu_model.fit_generator(datagen.flow(x_train, y_train,\n",
        "\t\t\t\t\t\t\t\t\t batch_size=64),\n",
        "\t\t\t\t\t\tsteps_per_epoch=782,epochs=250,verbose=1,validation_data=(x_test, y_test),callbacks=[lrschedular])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(8,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(8, 32, 32, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(8, 10), dtype=tf.float32, name='dense_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.10000000149011612, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': True}\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.SGD object at 0x7f4733a416d8> []\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 149.0614778995514 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "INFO:tensorflow:CPU -> TPU lr: 0.10000000149011612 {0.1}\n",
            "INFO:tensorflow:CPU -> TPU momentum: 0.8999999761581421 {0.9}\n",
            "INFO:tensorflow:CPU -> TPU decay: 0.0 {0.0}\n",
            "WARNING:tensorflow:Cannot update non-variable config: nesterov\n",
            " 33/782 [>.............................] - ETA: 1:54:52 - loss: 4.1414 - acc: 0.2235INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(2,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(2, 32, 32, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(2, 10), dtype=tf.float32, name='dense_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.SGD object at 0x7f4733a416d8> [<tf.Variable 'tpu_139943849692576/SGD/iterations:0' shape=() dtype=int64>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4719642940>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4719642e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4719642dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4719646a58>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47195aed30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47195d34e0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471959de80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471950afd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47194acc88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4719477da0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4719469ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47193b0c50>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47193ccf28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4719342d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471930ddd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47192b5ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471929bcf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4719268eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471920ce48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4719179d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4719144d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471916afd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47190d5e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471909fdd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4719044cc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718fb3f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718f7df60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718f9fdd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718f11518>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718ed1d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718e80400>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718e69be0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718db4f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718d7e278>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718d6a748>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718d14b70>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718cdae10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718c49f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718c6a160>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718bb8fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718ba4ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718b49f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718b10eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718a80fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718a4bc88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47189eea20>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47189dae48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47189a4ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718945dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47188b8c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718883eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47188a6f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718814d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47187ddd68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718782c50>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47186efd68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47186b7d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47186dcdd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471864fbe0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718614fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47185bacc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47185a85f8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47184f2ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47184bb208>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47184aaa90>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471844ffd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718414b38>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718382ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471832c0f0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47182ec908>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47182e3e80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718284d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471824fe48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47181c0f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718188c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47181aaeb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718116dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47180e2e80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4718087d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717ff6ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717fc0d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717fdfef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717f4fd30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717f1acf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717ec3fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717eabcf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717df7cc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717e18d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717d8a7b8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717d52d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717cf7e80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717ce25c0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717c34e80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717c53b38>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717bc2ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717b8cf60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717b53ac8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717ac3d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717ae4cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717a32eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717a1cfd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47179c2cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471798add8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47178fdf60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47178c3ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47178e9e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717855d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471781fe10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47177c5cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717732d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47176f9ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471771fe80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717689fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471765cd68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47175fdf60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47175e9e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717533e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717559cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47174c8f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717491f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717434e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717426518>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471736fd68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717390cc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47172fec18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47172c9f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47172932b0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47171f7780>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47172264a8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717171e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471715ef98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717100198>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47170c94a8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717037f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471705ef28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4717027ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716f94cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716f5dda0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716f03eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716e70cc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716e38f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716e60e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716dcecf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716d99ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716d3af98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716d26dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716c72da0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716c97c88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716c06f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716bcefd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716b73da0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716b65c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716aaccf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716ad1cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716a3cbe0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716a06f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47169cf240>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471693fe80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716962d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47168aeb70>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716899f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716841128>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471680d940>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716776eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471679bf28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716763e80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47166d4c88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471669df28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716642c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47165ade10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716577eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471659cda0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471650df60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47164d5ac8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716476f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716465d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47163aed30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47163d7c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716341cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471630ccf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47162b1da0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47162a2be0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471626ad68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716211c88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47161795c0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4716145eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47161131d0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47160d8f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47160a3f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471606ab00>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715fd7be0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715f7f9b0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715f4af98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715eb3fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715edad30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715ea3e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715e11c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715ddbf60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715d7ee80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715cecda0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715cb6e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715cdbd30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715c4cc50>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715c10f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715bb7eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715ba4cc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715aecfd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715b16f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715a7ecc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715a48e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47159f1d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47159de780>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47159a7fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471594de48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47158bb550>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715888e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47158a7470>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715815ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47157dffd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47157a9a90>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471571bd30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47156bd4e0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715686e80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47155f1fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715615c88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47155e0da0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471554fef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715519c50>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47154bff28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47154abd30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47153f4dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471541def0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715385cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715351eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47152f6e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47152e3d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471522dd30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715254fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47151bde10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4715188dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471512ccc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471511df28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47150e6f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471508add8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714ff9518>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714fc4d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714fe8400>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714f52be0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714f1ef60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714ee7278>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714e56748>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714dfab70>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714dc5e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714d30f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714d53160>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714d21fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714c8def0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714c33f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714bfbeb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714be8fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714b35c88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714b59a20>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714ac7e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714a8eef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714a33dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714a22c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471496deb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714990f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47148ffd68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47148c7d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47148ebc50>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714859d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714824d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47147c8dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714739be0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714702fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714725cc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47146935f8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471465cef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714624208>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714594a90>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714537fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47144feb38>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471446eef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47144950f0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714461908>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47143cae80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714372d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471433ae48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471432af28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714272c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714297eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714203dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47141cce80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714171d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714161ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f471412ad68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f47140ceef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f4714096ef0>]\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 96.00654864311218 secs\n",
            "781/782 [============================>.] - ETA: 0s - loss: 3.3095 - acc: 0.4268INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(8,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(8, 32, 32, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(8, 10), dtype=tf.float32, name='dense_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.10000000149011612, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': True}\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.SGD object at 0x7f46f6c17e10> []\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 69.93361067771912 secs\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(2,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(2, 32, 32, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(2, 10), dtype=tf.float32, name='dense_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.SGD object at 0x7f46f6c17e10> []\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 44.25811147689819 secs\n",
            "782/782 [==============================] - 707s 903ms/step - loss: 3.3089 - acc: 0.4270 - val_loss: 3.0119 - val_acc: 0.5262\n",
            "Epoch 2/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 2.4866 - acc: 0.5923 - val_loss: 2.5285 - val_acc: 0.5487\n",
            "Epoch 3/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 2.0048 - acc: 0.6692 - val_loss: 1.6994 - val_acc: 0.7224\n",
            "Epoch 4/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 1.6877 - acc: 0.7095 - val_loss: 1.5725 - val_acc: 0.7244\n",
            "Epoch 5/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 1.4745 - acc: 0.7386 - val_loss: 1.4269 - val_acc: 0.7263\n",
            "Epoch 6/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 1.3243 - acc: 0.7528 - val_loss: 1.2179 - val_acc: 0.7769\n",
            "Epoch 7/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 1.2170 - acc: 0.7677 - val_loss: 1.1484 - val_acc: 0.7819\n",
            "Epoch 8/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 1.1389 - acc: 0.7778 - val_loss: 1.0783 - val_acc: 0.7909\n",
            "Epoch 9/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 1.0830 - acc: 0.7834 - val_loss: 1.1013 - val_acc: 0.7744\n",
            "Epoch 10/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 1.0448 - acc: 0.7894 - val_loss: 1.1313 - val_acc: 0.7590\n",
            "Epoch 11/250\n",
            "782/782 [==============================] - 65s 84ms/step - loss: 1.0201 - acc: 0.7913 - val_loss: 1.1600 - val_acc: 0.7694\n",
            "Epoch 12/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.9966 - acc: 0.7961 - val_loss: 1.0054 - val_acc: 0.8015\n",
            "Epoch 13/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.9803 - acc: 0.8015 - val_loss: 0.9843 - val_acc: 0.8051\n",
            "Epoch 14/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.9696 - acc: 0.8041 - val_loss: 0.9353 - val_acc: 0.8204\n",
            "Epoch 15/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.9535 - acc: 0.8075 - val_loss: 1.0019 - val_acc: 0.8003\n",
            "Epoch 16/250\n",
            "782/782 [==============================] - 65s 84ms/step - loss: 0.9503 - acc: 0.8086 - val_loss: 1.1735 - val_acc: 0.7672\n",
            "Epoch 17/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.9473 - acc: 0.8078 - val_loss: 0.9543 - val_acc: 0.8177\n",
            "Epoch 18/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 0.9350 - acc: 0.8137 - val_loss: 1.1008 - val_acc: 0.7900\n",
            "Epoch 19/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.9346 - acc: 0.8134 - val_loss: 1.0517 - val_acc: 0.7857\n",
            "Epoch 20/250\n",
            "782/782 [==============================] - 67s 86ms/step - loss: 0.9252 - acc: 0.8186 - val_loss: 1.2564 - val_acc: 0.7528\n",
            "Epoch 21/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.9184 - acc: 0.8192 - val_loss: 1.2723 - val_acc: 0.7135\n",
            "Epoch 22/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 0.9169 - acc: 0.8212 - val_loss: 1.0967 - val_acc: 0.7740\n",
            "Epoch 23/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.9185 - acc: 0.8203 - val_loss: 1.2037 - val_acc: 0.7484\n",
            "Epoch 24/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.9141 - acc: 0.8235 - val_loss: 1.0220 - val_acc: 0.7928\n",
            "Epoch 25/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 0.9121 - acc: 0.8218 - val_loss: 1.1172 - val_acc: 0.7779\n",
            "Epoch 26/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.9081 - acc: 0.8238 - val_loss: 1.0376 - val_acc: 0.7970\n",
            "Epoch 27/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.9033 - acc: 0.8256 - val_loss: 0.9685 - val_acc: 0.8058\n",
            "Epoch 28/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.9038 - acc: 0.8259 - val_loss: 1.2232 - val_acc: 0.7562\n",
            "Epoch 29/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8974 - acc: 0.8284 - val_loss: 1.1303 - val_acc: 0.7676\n",
            "Epoch 30/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 0.8997 - acc: 0.8276 - val_loss: 0.9757 - val_acc: 0.8094\n",
            "Epoch 31/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 0.8936 - acc: 0.8298 - val_loss: 1.0867 - val_acc: 0.7630\n",
            "Epoch 32/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8935 - acc: 0.8308 - val_loss: 0.8590 - val_acc: 0.8430\n",
            "Epoch 33/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8880 - acc: 0.8309 - val_loss: 1.1029 - val_acc: 0.7833\n",
            "Epoch 34/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8868 - acc: 0.8329 - val_loss: 0.9653 - val_acc: 0.8136\n",
            "Epoch 35/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8906 - acc: 0.8326 - val_loss: 1.2689 - val_acc: 0.7455\n",
            "Epoch 36/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8866 - acc: 0.8323 - val_loss: 0.9350 - val_acc: 0.8283\n",
            "Epoch 37/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8871 - acc: 0.8324 - val_loss: 0.9562 - val_acc: 0.8116\n",
            "Epoch 38/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8812 - acc: 0.8354 - val_loss: 0.9182 - val_acc: 0.8333\n",
            "Epoch 39/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8843 - acc: 0.8348 - val_loss: 1.2729 - val_acc: 0.7522\n",
            "Epoch 40/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8783 - acc: 0.8355 - val_loss: 1.0054 - val_acc: 0.8045\n",
            "Epoch 41/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8748 - acc: 0.8378 - val_loss: 1.0180 - val_acc: 0.8107\n",
            "Epoch 42/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 0.8808 - acc: 0.8364 - val_loss: 0.9919 - val_acc: 0.8063\n",
            "Epoch 43/250\n",
            "782/782 [==============================] - 83s 107ms/step - loss: 0.8760 - acc: 0.8386 - val_loss: 0.9599 - val_acc: 0.8179\n",
            "Epoch 44/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8758 - acc: 0.8371 - val_loss: 1.2528 - val_acc: 0.7453\n",
            "Epoch 45/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8689 - acc: 0.8393 - val_loss: 0.9151 - val_acc: 0.8347\n",
            "Epoch 46/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8728 - acc: 0.8367 - val_loss: 0.9486 - val_acc: 0.8241\n",
            "Epoch 47/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8765 - acc: 0.8366 - val_loss: 0.9501 - val_acc: 0.8263\n",
            "Epoch 48/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8703 - acc: 0.8389 - val_loss: 1.3725 - val_acc: 0.7493\n",
            "Epoch 49/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8704 - acc: 0.8384 - val_loss: 0.9845 - val_acc: 0.8143\n",
            "Epoch 50/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8717 - acc: 0.8401 - val_loss: 0.9430 - val_acc: 0.8269\n",
            "Epoch 51/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8712 - acc: 0.8397 - val_loss: 1.1514 - val_acc: 0.7882\n",
            "Epoch 52/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8640 - acc: 0.8422 - val_loss: 0.9134 - val_acc: 0.8277\n",
            "Epoch 53/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 0.8711 - acc: 0.8396 - val_loss: 1.1205 - val_acc: 0.7864\n",
            "Epoch 54/250\n",
            "782/782 [==============================] - 65s 84ms/step - loss: 0.8650 - acc: 0.8424 - val_loss: 1.0028 - val_acc: 0.8159\n",
            "Epoch 55/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8618 - acc: 0.8409 - val_loss: 0.9070 - val_acc: 0.8313\n",
            "Epoch 56/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8695 - acc: 0.8391 - val_loss: 0.9448 - val_acc: 0.8106\n",
            "Epoch 57/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8657 - acc: 0.8420 - val_loss: 1.0747 - val_acc: 0.7922\n",
            "Epoch 58/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8664 - acc: 0.8430 - val_loss: 0.9370 - val_acc: 0.8236\n",
            "Epoch 59/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8629 - acc: 0.8423 - val_loss: 0.9234 - val_acc: 0.8300\n",
            "Epoch 60/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8622 - acc: 0.8438 - val_loss: 0.8755 - val_acc: 0.8466\n",
            "Epoch 61/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 0.8651 - acc: 0.8427 - val_loss: 0.9367 - val_acc: 0.8227\n",
            "Epoch 62/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8620 - acc: 0.8426 - val_loss: 0.9658 - val_acc: 0.8184\n",
            "Epoch 63/250\n",
            "782/782 [==============================] - 65s 84ms/step - loss: 0.8600 - acc: 0.8440 - val_loss: 0.9950 - val_acc: 0.8032\n",
            "Epoch 64/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8560 - acc: 0.8420 - val_loss: 0.8789 - val_acc: 0.8343\n",
            "Epoch 65/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8608 - acc: 0.8429 - val_loss: 1.1307 - val_acc: 0.7841\n",
            "Epoch 66/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8582 - acc: 0.8429 - val_loss: 0.9936 - val_acc: 0.8091\n",
            "Epoch 67/250\n",
            "782/782 [==============================] - 65s 83ms/step - loss: 0.8534 - acc: 0.8449 - val_loss: 0.9358 - val_acc: 0.8191\n",
            "Epoch 68/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8596 - acc: 0.8431 - val_loss: 0.9413 - val_acc: 0.8235\n",
            "Epoch 69/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8566 - acc: 0.8438 - val_loss: 1.0203 - val_acc: 0.8119\n",
            "Epoch 70/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8587 - acc: 0.8439 - val_loss: 1.3396 - val_acc: 0.7423\n",
            "Epoch 71/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8533 - acc: 0.8467 - val_loss: 0.8900 - val_acc: 0.8396\n",
            "Epoch 72/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8572 - acc: 0.8435 - val_loss: 0.9891 - val_acc: 0.8141\n",
            "Epoch 73/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8553 - acc: 0.8459 - val_loss: 0.8359 - val_acc: 0.8559\n",
            "Epoch 74/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8538 - acc: 0.8473 - val_loss: 1.1827 - val_acc: 0.7672\n",
            "Epoch 75/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8481 - acc: 0.8486 - val_loss: 1.2244 - val_acc: 0.7482\n",
            "Epoch 76/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8469 - acc: 0.8476 - val_loss: 0.8456 - val_acc: 0.8463\n",
            "Epoch 77/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8517 - acc: 0.8460 - val_loss: 0.8652 - val_acc: 0.8422\n",
            "Epoch 78/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8529 - acc: 0.8453 - val_loss: 1.0116 - val_acc: 0.8012\n",
            "Epoch 79/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8511 - acc: 0.8467 - val_loss: 0.9004 - val_acc: 0.8268\n",
            "Epoch 80/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8488 - acc: 0.8468 - val_loss: 0.9156 - val_acc: 0.8215\n",
            "Epoch 81/250\n",
            "782/782 [==============================] - 67s 86ms/step - loss: 0.8542 - acc: 0.8442 - val_loss: 1.2110 - val_acc: 0.7733\n",
            "Epoch 82/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8479 - acc: 0.8463 - val_loss: 0.9008 - val_acc: 0.8333\n",
            "Epoch 83/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8489 - acc: 0.8482 - val_loss: 0.8372 - val_acc: 0.8487\n",
            "Epoch 84/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8507 - acc: 0.8472 - val_loss: 1.3078 - val_acc: 0.7534\n",
            "Epoch 85/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8555 - acc: 0.8464 - val_loss: 1.1138 - val_acc: 0.7877\n",
            "Epoch 86/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8491 - acc: 0.8469 - val_loss: 0.8515 - val_acc: 0.8467\n",
            "Epoch 87/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8448 - acc: 0.8474 - val_loss: 1.1709 - val_acc: 0.7775\n",
            "Epoch 88/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8438 - acc: 0.8498 - val_loss: 0.8569 - val_acc: 0.8456\n",
            "Epoch 89/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 0.8381 - acc: 0.8509 - val_loss: 1.2720 - val_acc: 0.7487\n",
            "Epoch 90/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8426 - acc: 0.8478 - val_loss: 1.0105 - val_acc: 0.8164\n",
            "Epoch 91/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8477 - acc: 0.8479 - val_loss: 1.0093 - val_acc: 0.8162\n",
            "Epoch 92/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8430 - acc: 0.8499 - val_loss: 1.2471 - val_acc: 0.7384\n",
            "Epoch 93/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8442 - acc: 0.8487 - val_loss: 0.8746 - val_acc: 0.8383\n",
            "Epoch 94/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8419 - acc: 0.8497 - val_loss: 1.1175 - val_acc: 0.7830\n",
            "Epoch 95/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8440 - acc: 0.8482 - val_loss: 1.2058 - val_acc: 0.7781\n",
            "Epoch 96/250\n",
            "782/782 [==============================] - 65s 84ms/step - loss: 0.8441 - acc: 0.8503 - val_loss: 1.0624 - val_acc: 0.7934\n",
            "Epoch 97/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8354 - acc: 0.8517 - val_loss: 0.9161 - val_acc: 0.8280\n",
            "Epoch 98/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8434 - acc: 0.8479 - val_loss: 1.0129 - val_acc: 0.8128\n",
            "Epoch 99/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8424 - acc: 0.8510 - val_loss: 0.9059 - val_acc: 0.8322\n",
            "Epoch 100/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8393 - acc: 0.8505 - val_loss: 0.9039 - val_acc: 0.8387\n",
            "Epoch 101/250\n",
            "782/782 [==============================] - 65s 83ms/step - loss: 0.8470 - acc: 0.8473 - val_loss: 1.2270 - val_acc: 0.7582\n",
            "Epoch 102/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8425 - acc: 0.8497 - val_loss: 0.9859 - val_acc: 0.8033\n",
            "Epoch 103/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8402 - acc: 0.8504 - val_loss: 1.1194 - val_acc: 0.7891\n",
            "Epoch 104/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8411 - acc: 0.8485 - val_loss: 1.0617 - val_acc: 0.7945\n",
            "Epoch 105/250\n",
            "782/782 [==============================] - 65s 83ms/step - loss: 0.8424 - acc: 0.8510 - val_loss: 0.9974 - val_acc: 0.8081\n",
            "Epoch 106/250\n",
            "782/782 [==============================] - 65s 84ms/step - loss: 0.8364 - acc: 0.8531 - val_loss: 1.2549 - val_acc: 0.7552\n",
            "Epoch 107/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8388 - acc: 0.8513 - val_loss: 1.0056 - val_acc: 0.8078\n",
            "Epoch 108/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 0.8391 - acc: 0.8503 - val_loss: 0.9382 - val_acc: 0.8277\n",
            "Epoch 109/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8423 - acc: 0.8515 - val_loss: 1.2078 - val_acc: 0.7565\n",
            "Epoch 110/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8387 - acc: 0.8513 - val_loss: 0.9512 - val_acc: 0.8207\n",
            "Epoch 111/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8409 - acc: 0.8518 - val_loss: 0.9346 - val_acc: 0.8310\n",
            "Epoch 112/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8340 - acc: 0.8529 - val_loss: 0.8405 - val_acc: 0.8500\n",
            "Epoch 113/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8375 - acc: 0.8502 - val_loss: 0.9206 - val_acc: 0.8203\n",
            "Epoch 114/250\n",
            "782/782 [==============================] - 65s 84ms/step - loss: 0.8342 - acc: 0.8509 - val_loss: 1.0897 - val_acc: 0.7885\n",
            "Epoch 115/250\n",
            "782/782 [==============================] - 65s 84ms/step - loss: 0.8418 - acc: 0.8502 - val_loss: 1.1766 - val_acc: 0.7750\n",
            "Epoch 116/250\n",
            "782/782 [==============================] - 65s 83ms/step - loss: 0.8382 - acc: 0.8520 - val_loss: 0.9105 - val_acc: 0.8243\n",
            "Epoch 117/250\n",
            "782/782 [==============================] - 65s 84ms/step - loss: 0.8403 - acc: 0.8496 - val_loss: 0.9955 - val_acc: 0.8132\n",
            "Epoch 118/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8379 - acc: 0.8508 - val_loss: 1.2983 - val_acc: 0.7098\n",
            "Epoch 119/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.8341 - acc: 0.8531 - val_loss: 1.4438 - val_acc: 0.7232\n",
            "Epoch 120/250\n",
            "782/782 [==============================] - 65s 83ms/step - loss: 0.8330 - acc: 0.8520 - val_loss: 1.0871 - val_acc: 0.7831\n",
            "Epoch 121/250\n",
            "782/782 [==============================] - 65s 84ms/step - loss: 0.8399 - acc: 0.8512 - val_loss: 1.0210 - val_acc: 0.8046\n",
            "Epoch 122/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8315 - acc: 0.8540 - val_loss: 0.8632 - val_acc: 0.8453\n",
            "Epoch 123/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8307 - acc: 0.8511 - val_loss: 1.1758 - val_acc: 0.7695\n",
            "Epoch 124/250\n",
            "782/782 [==============================] - 65s 84ms/step - loss: 0.8335 - acc: 0.8520 - val_loss: 1.0864 - val_acc: 0.7840\n",
            "Epoch 125/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.8310 - acc: 0.8532 - val_loss: 0.9371 - val_acc: 0.8295\n",
            "Epoch 126/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.6882 - acc: 0.9004 - val_loss: 0.6127 - val_acc: 0.9233\n",
            "Epoch 127/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.6234 - acc: 0.9180 - val_loss: 0.5994 - val_acc: 0.9239\n",
            "Epoch 128/250\n",
            "782/782 [==============================] - 65s 84ms/step - loss: 0.6002 - acc: 0.9234 - val_loss: 0.5785 - val_acc: 0.9282\n",
            "Epoch 129/250\n",
            "782/782 [==============================] - 65s 84ms/step - loss: 0.5767 - acc: 0.9276 - val_loss: 0.5626 - val_acc: 0.9316\n",
            "Epoch 130/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.5587 - acc: 0.9320 - val_loss: 0.5658 - val_acc: 0.9275\n",
            "Epoch 131/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.5453 - acc: 0.9339 - val_loss: 0.5446 - val_acc: 0.9299\n",
            "Epoch 132/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.5286 - acc: 0.9356 - val_loss: 0.5401 - val_acc: 0.9309\n",
            "Epoch 133/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.5170 - acc: 0.9376 - val_loss: 0.5400 - val_acc: 0.9281\n",
            "Epoch 134/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.5061 - acc: 0.9393 - val_loss: 0.5253 - val_acc: 0.9319\n",
            "Epoch 135/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.4997 - acc: 0.9387 - val_loss: 0.5166 - val_acc: 0.9331\n",
            "Epoch 136/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 0.4874 - acc: 0.9400 - val_loss: 0.5198 - val_acc: 0.9311\n",
            "Epoch 137/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.4752 - acc: 0.9419 - val_loss: 0.5215 - val_acc: 0.9290\n",
            "Epoch 138/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.4694 - acc: 0.9420 - val_loss: 0.5010 - val_acc: 0.9310\n",
            "Epoch 139/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.4568 - acc: 0.9441 - val_loss: 0.4845 - val_acc: 0.9346\n",
            "Epoch 140/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.4510 - acc: 0.9432 - val_loss: 0.4814 - val_acc: 0.9343\n",
            "Epoch 141/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.4458 - acc: 0.9443 - val_loss: 0.4917 - val_acc: 0.9301\n",
            "Epoch 142/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.4376 - acc: 0.9444 - val_loss: 0.4647 - val_acc: 0.9361\n",
            "Epoch 143/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.4306 - acc: 0.9452 - val_loss: 0.4785 - val_acc: 0.9309\n",
            "Epoch 144/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.4294 - acc: 0.9441 - val_loss: 0.4741 - val_acc: 0.9320\n",
            "Epoch 145/250\n",
            "782/782 [==============================] - 65s 83ms/step - loss: 0.4194 - acc: 0.9461 - val_loss: 0.4572 - val_acc: 0.9346\n",
            "Epoch 146/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 0.4163 - acc: 0.9444 - val_loss: 0.4620 - val_acc: 0.9319\n",
            "Epoch 147/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.4089 - acc: 0.9462 - val_loss: 0.4612 - val_acc: 0.9313\n",
            "Epoch 148/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.4027 - acc: 0.9474 - val_loss: 0.4623 - val_acc: 0.9282\n",
            "Epoch 149/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.4018 - acc: 0.9466 - val_loss: 0.4405 - val_acc: 0.9355\n",
            "Epoch 150/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.3993 - acc: 0.9460 - val_loss: 0.4685 - val_acc: 0.9243\n",
            "Epoch 151/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.3950 - acc: 0.9456 - val_loss: 0.4456 - val_acc: 0.9318\n",
            "Epoch 152/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.3885 - acc: 0.9466 - val_loss: 0.4304 - val_acc: 0.9339\n",
            "Epoch 153/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.3857 - acc: 0.9462 - val_loss: 0.4591 - val_acc: 0.9267\n",
            "Epoch 154/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.3879 - acc: 0.9447 - val_loss: 0.4627 - val_acc: 0.9280\n",
            "Epoch 155/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.3794 - acc: 0.9467 - val_loss: 0.4805 - val_acc: 0.9182\n",
            "Epoch 156/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.3791 - acc: 0.9456 - val_loss: 0.4757 - val_acc: 0.9195\n",
            "Epoch 157/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.3719 - acc: 0.9479 - val_loss: 0.4448 - val_acc: 0.9276\n",
            "Epoch 158/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.3704 - acc: 0.9489 - val_loss: 0.4519 - val_acc: 0.9253\n",
            "Epoch 159/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.3692 - acc: 0.9474 - val_loss: 0.4362 - val_acc: 0.9282\n",
            "Epoch 160/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.3671 - acc: 0.9473 - val_loss: 0.4327 - val_acc: 0.9312\n",
            "Epoch 161/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 0.3699 - acc: 0.9450 - val_loss: 0.4544 - val_acc: 0.9204\n",
            "Epoch 162/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.3671 - acc: 0.9466 - val_loss: 0.4628 - val_acc: 0.9187\n",
            "Epoch 163/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.3617 - acc: 0.9470 - val_loss: 0.4116 - val_acc: 0.9329\n",
            "Epoch 164/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 0.3621 - acc: 0.9465 - val_loss: 0.4521 - val_acc: 0.9193\n",
            "Epoch 165/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.3578 - acc: 0.9488 - val_loss: 0.4497 - val_acc: 0.9219\n",
            "Epoch 166/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.3598 - acc: 0.9470 - val_loss: 0.4334 - val_acc: 0.9272\n",
            "Epoch 167/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.3600 - acc: 0.9461 - val_loss: 0.4517 - val_acc: 0.9234\n",
            "Epoch 168/250\n",
            "782/782 [==============================] - 65s 83ms/step - loss: 0.3588 - acc: 0.9468 - val_loss: 0.5467 - val_acc: 0.8966\n",
            "Epoch 169/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.3531 - acc: 0.9475 - val_loss: 0.4113 - val_acc: 0.9331\n",
            "Epoch 170/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.3561 - acc: 0.9462 - val_loss: 0.4492 - val_acc: 0.9204\n",
            "Epoch 171/250\n",
            "782/782 [==============================] - 65s 83ms/step - loss: 0.3544 - acc: 0.9460 - val_loss: 0.5187 - val_acc: 0.9023\n",
            "Epoch 172/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.3504 - acc: 0.9469 - val_loss: 0.4483 - val_acc: 0.9208\n",
            "Epoch 173/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.3547 - acc: 0.9453 - val_loss: 0.4355 - val_acc: 0.9243\n",
            "Epoch 174/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.3474 - acc: 0.9487 - val_loss: 0.4274 - val_acc: 0.9294\n",
            "Epoch 175/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.3514 - acc: 0.9465 - val_loss: 0.4320 - val_acc: 0.9231\n",
            "Epoch 176/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.3539 - acc: 0.9450 - val_loss: 0.4781 - val_acc: 0.9105\n",
            "Epoch 177/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.3500 - acc: 0.9469 - val_loss: 0.3958 - val_acc: 0.9366\n",
            "Epoch 178/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.3505 - acc: 0.9465 - val_loss: 0.4071 - val_acc: 0.9310\n",
            "Epoch 179/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.3486 - acc: 0.9480 - val_loss: 0.4123 - val_acc: 0.9297\n",
            "Epoch 180/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.3510 - acc: 0.9456 - val_loss: 0.4202 - val_acc: 0.9272\n",
            "Epoch 181/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.3447 - acc: 0.9483 - val_loss: 0.4121 - val_acc: 0.9285\n",
            "Epoch 182/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.3459 - acc: 0.9471 - val_loss: 0.4512 - val_acc: 0.9214\n",
            "Epoch 183/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.3457 - acc: 0.9475 - val_loss: 0.4902 - val_acc: 0.9096\n",
            "Epoch 184/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.3429 - acc: 0.9479 - val_loss: 0.4904 - val_acc: 0.9074\n",
            "Epoch 185/250\n",
            "782/782 [==============================] - 65s 83ms/step - loss: 0.3454 - acc: 0.9473 - val_loss: 0.4098 - val_acc: 0.9310\n",
            "Epoch 186/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.3420 - acc: 0.9484 - val_loss: 0.5035 - val_acc: 0.9068\n",
            "Epoch 187/250\n",
            "782/782 [==============================] - 65s 84ms/step - loss: 0.3431 - acc: 0.9476 - val_loss: 0.4543 - val_acc: 0.9174\n",
            "Epoch 188/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 0.3037 - acc: 0.9619 - val_loss: 0.3561 - val_acc: 0.9477\n",
            "Epoch 189/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2841 - acc: 0.9684 - val_loss: 0.3569 - val_acc: 0.9482\n",
            "Epoch 190/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2761 - acc: 0.9708 - val_loss: 0.3517 - val_acc: 0.9491\n",
            "Epoch 191/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2701 - acc: 0.9738 - val_loss: 0.3554 - val_acc: 0.9478\n",
            "Epoch 192/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2689 - acc: 0.9736 - val_loss: 0.3511 - val_acc: 0.9493\n",
            "Epoch 193/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2647 - acc: 0.9755 - val_loss: 0.3506 - val_acc: 0.9483\n",
            "Epoch 194/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2645 - acc: 0.9750 - val_loss: 0.3476 - val_acc: 0.9499\n",
            "Epoch 195/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 0.2599 - acc: 0.9769 - val_loss: 0.3467 - val_acc: 0.9496\n",
            "Epoch 196/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2576 - acc: 0.9772 - val_loss: 0.3490 - val_acc: 0.9492\n",
            "Epoch 197/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2535 - acc: 0.9787 - val_loss: 0.3426 - val_acc: 0.9517\n",
            "Epoch 198/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2543 - acc: 0.9787 - val_loss: 0.3489 - val_acc: 0.9498\n",
            "Epoch 199/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 0.2497 - acc: 0.9793 - val_loss: 0.3453 - val_acc: 0.9513\n",
            "Epoch 200/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2503 - acc: 0.9789 - val_loss: 0.3449 - val_acc: 0.9504\n",
            "Epoch 201/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2495 - acc: 0.9784 - val_loss: 0.3408 - val_acc: 0.9531\n",
            "Epoch 202/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2472 - acc: 0.9794 - val_loss: 0.3480 - val_acc: 0.9498\n",
            "Epoch 203/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2469 - acc: 0.9793 - val_loss: 0.3479 - val_acc: 0.9496\n",
            "Epoch 204/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2439 - acc: 0.9798 - val_loss: 0.3443 - val_acc: 0.9509\n",
            "Epoch 205/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2410 - acc: 0.9822 - val_loss: 0.3402 - val_acc: 0.9515\n",
            "Epoch 206/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2421 - acc: 0.9810 - val_loss: 0.3430 - val_acc: 0.9507\n",
            "Epoch 207/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2406 - acc: 0.9816 - val_loss: 0.3420 - val_acc: 0.9512\n",
            "Epoch 208/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2399 - acc: 0.9809 - val_loss: 0.3372 - val_acc: 0.9518\n",
            "Epoch 209/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2405 - acc: 0.9810 - val_loss: 0.3373 - val_acc: 0.9508\n",
            "Epoch 210/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 0.2387 - acc: 0.9814 - val_loss: 0.3468 - val_acc: 0.9491\n",
            "Epoch 211/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2380 - acc: 0.9822 - val_loss: 0.3453 - val_acc: 0.9498\n",
            "Epoch 212/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2353 - acc: 0.9832 - val_loss: 0.3458 - val_acc: 0.9473\n",
            "Epoch 213/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2344 - acc: 0.9824 - val_loss: 0.3440 - val_acc: 0.9499\n",
            "Epoch 214/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2347 - acc: 0.9821 - val_loss: 0.3380 - val_acc: 0.9515\n",
            "Epoch 215/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2338 - acc: 0.9824 - val_loss: 0.3379 - val_acc: 0.9526\n",
            "Epoch 216/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2319 - acc: 0.9827 - val_loss: 0.3411 - val_acc: 0.9508\n",
            "Epoch 217/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2310 - acc: 0.9837 - val_loss: 0.3401 - val_acc: 0.9503\n",
            "Epoch 218/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2308 - acc: 0.9837 - val_loss: 0.3436 - val_acc: 0.9502\n",
            "Epoch 219/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2305 - acc: 0.9829 - val_loss: 0.3385 - val_acc: 0.9522\n",
            "Epoch 220/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2287 - acc: 0.9837 - val_loss: 0.3337 - val_acc: 0.9518\n",
            "Epoch 221/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2281 - acc: 0.9839 - val_loss: 0.3390 - val_acc: 0.9507\n",
            "Epoch 222/250\n",
            "782/782 [==============================] - 65s 84ms/step - loss: 0.2270 - acc: 0.9835 - val_loss: 0.3381 - val_acc: 0.9518\n",
            "Epoch 223/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2280 - acc: 0.9834 - val_loss: 0.3295 - val_acc: 0.9526\n",
            "Epoch 224/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2277 - acc: 0.9830 - val_loss: 0.3358 - val_acc: 0.9519\n",
            "Epoch 225/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2255 - acc: 0.9837 - val_loss: 0.3332 - val_acc: 0.9505\n",
            "Epoch 226/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2240 - acc: 0.9842 - val_loss: 0.3347 - val_acc: 0.9508\n",
            "Epoch 227/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2196 - acc: 0.9860 - val_loss: 0.3341 - val_acc: 0.9510\n",
            "Epoch 228/250\n",
            "782/782 [==============================] - 65s 83ms/step - loss: 0.2201 - acc: 0.9857 - val_loss: 0.3322 - val_acc: 0.9512\n",
            "Epoch 229/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2223 - acc: 0.9851 - val_loss: 0.3329 - val_acc: 0.9508\n",
            "Epoch 230/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2209 - acc: 0.9855 - val_loss: 0.3334 - val_acc: 0.9508\n",
            "Epoch 231/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2186 - acc: 0.9859 - val_loss: 0.3319 - val_acc: 0.9515\n",
            "Epoch 232/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2186 - acc: 0.9862 - val_loss: 0.3335 - val_acc: 0.9516\n",
            "Epoch 233/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2189 - acc: 0.9861 - val_loss: 0.3322 - val_acc: 0.9517\n",
            "Epoch 234/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2183 - acc: 0.9863 - val_loss: 0.3330 - val_acc: 0.9516\n",
            "Epoch 235/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2191 - acc: 0.9858 - val_loss: 0.3328 - val_acc: 0.9505\n",
            "Epoch 236/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2184 - acc: 0.9862 - val_loss: 0.3334 - val_acc: 0.9515\n",
            "Epoch 237/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2179 - acc: 0.9861 - val_loss: 0.3327 - val_acc: 0.9516\n",
            "Epoch 238/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2188 - acc: 0.9865 - val_loss: 0.3316 - val_acc: 0.9519\n",
            "Epoch 239/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2184 - acc: 0.9861 - val_loss: 0.3322 - val_acc: 0.9517\n",
            "Epoch 240/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 0.2192 - acc: 0.9855 - val_loss: 0.3320 - val_acc: 0.9522\n",
            "Epoch 241/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 0.2184 - acc: 0.9858 - val_loss: 0.3314 - val_acc: 0.9527\n",
            "Epoch 242/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2179 - acc: 0.9864 - val_loss: 0.3295 - val_acc: 0.9523\n",
            "Epoch 243/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2178 - acc: 0.9864 - val_loss: 0.3313 - val_acc: 0.9526\n",
            "Epoch 244/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 0.2187 - acc: 0.9857 - val_loss: 0.3301 - val_acc: 0.9528\n",
            "Epoch 245/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2159 - acc: 0.9877 - val_loss: 0.3303 - val_acc: 0.9526\n",
            "Epoch 246/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2187 - acc: 0.9860 - val_loss: 0.3304 - val_acc: 0.9524\n",
            "Epoch 247/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2178 - acc: 0.9856 - val_loss: 0.3312 - val_acc: 0.9520\n",
            "Epoch 248/250\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 0.2152 - acc: 0.9872 - val_loss: 0.3317 - val_acc: 0.9522\n",
            "Epoch 249/250\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.2158 - acc: 0.9874 - val_loss: 0.3294 - val_acc: 0.9525\n",
            "Epoch 250/250\n",
            "782/782 [==============================] - 66s 85ms/step - loss: 0.2154 - acc: 0.9870 - val_loss: 0.3299 - val_acc: 0.9522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4746e1c438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZcWydmIVhZGr",
        "outputId": "81175f62-df0e-4484-f420-91fd5e0ac2e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = tpu_model.evaluate(x_test, y_test, verbose=1)\n",
        "print(score)\n",
        "print('Test loss: %.3f ' % (score[0]))\n",
        "print('Test accuracy: %.3f ' % (score[1]*100))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(4,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(4, 32, 32, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(4, 10), dtype=tf.float32, name='dense_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.SGD object at 0x7f46f6c17e10> []\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 47.78974199295044 secs\n",
            "10000/10000 [==============================] - 77s 8ms/step\n",
            "[0.3293477731704712, 0.953]\n",
            "Test loss: 0.329 \n",
            "Test accuracy: 95.300 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UE3lF6EH1r_L",
        "outputId": "4c964d2b-88b3-42f9-b93b-caefaf87a1cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "tpu_model.save_weights(\"DNST_weights_Shravan_B9.h5\")\n",
        "tpu_model.save(\"DNST_model_Shravan_B9.hdf5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 9.999999747378752e-05\n",
            "INFO:tensorflow:TPU -> CPU momentum: 0.8999999761581421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Og56VCRh5j8V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VmSIqsez3C-o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "1. Original Densenet Paper: https://arxiv.org/pdf/1608.06993\n",
        "2. https://medium.com/intuitionmachine/notes-on-the-implementation-densenet-in-tensorflow-beeda9dd1504\n",
        "3. https://forums.fast.ai/t/training-a-model-from-scratch-cifar-10/7897\n",
        "4. https://towardsdatascience.com/densenet-2810936aeebb\n",
        "5. https://towardsdatascience.com/normalized-direction-preserving-adam-switching-from-adam-to-sgd-and-nesterov-momentum-adam-with-460be5ddf686\n",
        "\n",
        "\n",
        "# Densenet implementations\n",
        "1. Original Densenet Implementation: https://github.com/liuzhuang13/DenseNet\n",
        "2. Fast.ai: http://files.fast.ai/part2/lesson13/densenet-keras.ipynb\n",
        "3. Github Users\n",
        "\ta. https://github.com/titu1994/DenseNet\n",
        "\tb. https://github.com/flyyufelix/DenseNet-Keras \n",
        "\n",
        "# LR Callbacks\n",
        "1. Cyclic Learning Rate: https://github.com/bckenstler/CLR\n",
        "2. SGDR: https://gist.github.com/t2kasa/490610116ddb0f3b664458d0e086e643\n",
        "3. SWATS: https://arxiv.org/pdf/1712.07628 (Implementation not found)\n",
        "\thttps://github.com/kweonwooj/papers/issues/76\n",
        "\thttps://www.groundai.com/project/improving-generalization-performance-by-switching-from-adam-to-sgd/\n",
        "\t"
      ]
    }
  ]
}