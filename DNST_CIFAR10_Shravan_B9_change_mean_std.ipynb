{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNST_CIFAR10_Shravan_B9_change_mean_std.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "K70hAckqg0EA",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "# !pip install -q keras\n",
        "# import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wVIx_KIigxPV",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, Activation,GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler,ModelCheckpoint,ReduceLROnPlateau\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UNHw6luQg3gc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# # backend\n",
        "# import tensorflow as tf\n",
        "# from keras import backend as k\n",
        "\n",
        "# # Don't pre-allocate memory; allocate as-needed\n",
        "# config = tf.ConfigProto()\n",
        "# config.gpu_options.allow_growth = True\n",
        "\n",
        "# # Create a session with the above options specified.\n",
        "# k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dsO_yGxcg5D8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 250\n",
        "l = 16\n",
        "num_filter = 32\n",
        "growth_rate = 12\n",
        "compression = 0.5\n",
        "dropout_rate = 0.2\n",
        "weight_decay = 1e-4\n",
        "dilate_rate = 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "st4sgt4xYllu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "#x = np.vstack((x_train, x_test))\n",
        "for i in range(3):\n",
        "\t\tmean = np.mean(x_train[:, :, :, i])\n",
        "\t\tstd = np.std(x_train[:, :, :, i])\n",
        "\t\tx_train[:, :, :, i] = (x_train[:, :, :, i] - mean) / std\n",
        "\t\tx_test[:, :, :, i] = (x_test[:, :, :, i] - mean) / std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ee-sge5Kg7vr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression, weight_decay, growth_rate\n",
        "\n",
        "    temp = input\n",
        "    \n",
        "    for _ in range(l):\n",
        "      \n",
        "        BatchNorm = BatchNormalization(gamma_regularizer=l2(weight_decay),beta_regularizer=l2(weight_decay))(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_1_1 = Conv2D(int(growth_rate*4), (1,1), use_bias=False ,padding='same',\n",
        "                              kernel_initializer='he_uniform',kernel_regularizer=l2(weight_decay))(relu)\n",
        "        \n",
        "        BatchNorm_1_1 = BatchNormalization(gamma_regularizer=l2(weight_decay),beta_regularizer=l2(weight_decay))(Conv2D_1_1)\n",
        "        relu_1_1 = Activation('relu')(BatchNorm_1_1)\n",
        "        Conv2D_3_3 = Conv2D(int(growth_rate), (3,3), use_bias=False ,padding='same', dilation_rate = dilate_rate,\n",
        "                              kernel_initializer='he_uniform',kernel_regularizer=l2(weight_decay))(relu_1_1)\n",
        "        \n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(rate=dropout_rate)(Conv2D_3_3)\n",
        "        \n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        num_filter += growth_rate\n",
        "        \n",
        "    return temp , num_filter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OOP6IPsGhBwb",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression, weight_decay\n",
        "    BatchNorm = BatchNormalization(gamma_regularizer=l2(weight_decay),beta_regularizer=l2(weight_decay))(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same',\n",
        "                              kernel_initializer='he_uniform',kernel_regularizer=l2(weight_decay))(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(rate=dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2),strides=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0RaKFpubhDIC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression, weight_decay\n",
        "    BatchNorm = BatchNormalization(gamma_regularizer=l2(weight_decay),beta_regularizer=l2(weight_decay))(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    #AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    #flat = Flatten()(AvgPooling)\n",
        "    #output = Dense(num_classes, activation='softmax')(flat)\n",
        "    GloAvgPooling = GlobalAveragePooling2D()(relu)\n",
        "    output = Dense(num_classes, activation='softmax',\n",
        "\t\tkernel_regularizer=l2(weight_decay),bias_regularizer=l2(weight_decay))(GloAvgPooling)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "anPCpQWhhGb7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "input = Input(shape=(img_height, img_width, channel))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same', dilation_rate = dilate_rate,\n",
        "\t\t\tkernel_initializer='he_uniform',kernel_regularizer=l2(weight_decay))(input)\n",
        "\n",
        "First_Block, num_filters = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filters, dropout_rate)\n",
        "\n",
        "Second_Block,num_filters = add_denseblock(First_Transition, num_filters, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filters, dropout_rate)\n",
        "\n",
        "# Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "# Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block,num_filters = add_denseblock(Second_Transition,  num_filters, dropout_rate)\n",
        "output = output_layer(Last_Block)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1kFh7pdxhNtT",
        "outputId": "999eb95f-9089-4c1d-92dc-1ee8f06d5f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 14552
        }
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 32)   128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 48)   1536        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 48)   192         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 48)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 12)   5184        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 32, 32, 12)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 44)   0           conv2d[0][0]                     \n",
            "                                                                 dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 44)   176         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 44)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 48)   2112        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 48)   192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 48)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 12)   5184        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 12)   0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 56)   0           concatenate[0][0]                \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 56)   224         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 56)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 48)   2688        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 48)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 48)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 12)   5184        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 32, 12)   0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 68)   0           concatenate_1[0][0]              \n",
            "                                                                 dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 68)   272         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 68)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 48)   3264        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 48)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 48)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 12)   5184        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32, 32, 12)   0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 80)   0           concatenate_2[0][0]              \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 80)   320         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 80)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 48)   3840        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 48)   192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 48)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 12)   5184        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32, 32, 12)   0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 92)   0           concatenate_3[0][0]              \n",
            "                                                                 dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 92)   368         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 92)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 48)   4416        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 48)   192         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 48)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 12)   5184        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 32, 32, 12)   0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 104)  0           concatenate_4[0][0]              \n",
            "                                                                 dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 104)  416         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 104)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 48)   4992        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 48)   192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 12)   5184        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 32, 32, 12)   0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 116)  0           concatenate_5[0][0]              \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 116)  464         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 116)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 48)   5568        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 48)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 48)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 12)   5184        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 32, 32, 12)   0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 128)  0           concatenate_6[0][0]              \n",
            "                                                                 dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 128)  512         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 128)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 48)   6144        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 48)   192         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 32, 48)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 12)   5184        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 32, 32, 12)   0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 140)  0           concatenate_7[0][0]              \n",
            "                                                                 dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 32, 140)  560         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 32, 32, 140)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 48)   6720        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 48)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 48)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 12)   5184        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 32, 32, 12)   0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 152)  0           concatenate_8[0][0]              \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 152)  608         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 152)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 48)   7296        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 32, 32, 48)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 32, 48)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 32, 32, 12)   5184        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 32, 32, 12)   0           conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 164)  0           concatenate_9[0][0]              \n",
            "                                                                 dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 32, 32, 164)  656         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 32, 32, 164)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 32, 32, 48)   7872        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 32, 32, 48)   192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 32, 32, 48)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 32, 32, 12)   5184        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 32, 32, 12)   0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 176)  0           concatenate_10[0][0]             \n",
            "                                                                 dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 32, 32, 176)  704         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 32, 32, 176)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 32, 32, 48)   8448        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 32, 32, 48)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 32, 32, 48)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 32, 32, 12)   5184        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 32, 32, 12)   0           conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 32, 32, 188)  0           concatenate_11[0][0]             \n",
            "                                                                 dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 32, 32, 188)  752         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 32, 32, 188)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 32, 32, 48)   9024        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 32, 32, 48)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 32, 32, 48)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 32, 32, 12)   5184        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 32, 32, 12)   0           conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 32, 32, 200)  0           concatenate_12[0][0]             \n",
            "                                                                 dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 32, 32, 200)  800         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 32, 32, 200)  0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 32, 32, 48)   9600        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 32, 32, 48)   192         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 32, 32, 48)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 32, 32, 12)   5184        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 32, 32, 12)   0           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 32, 32, 212)  0           concatenate_13[0][0]             \n",
            "                                                                 dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 32, 32, 212)  848         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 32, 32, 212)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 32, 32, 48)   10176       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 32, 32, 48)   192         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 32, 32, 48)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 32, 32, 12)   5184        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 32, 32, 12)   0           conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 32, 32, 224)  0           concatenate_14[0][0]             \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 32, 32, 224)  896         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 32, 32, 224)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 32, 32, 112)  25088       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 32, 32, 112)  0           conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 112)  0           dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 16, 16, 112)  448         average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 16, 16, 112)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 16, 16, 48)   5376        activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 16, 16, 48)   192         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 16, 16, 48)   0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 16, 16, 12)   5184        activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 16, 16, 12)   0           conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 16, 16, 124)  0           average_pooling2d[0][0]          \n",
            "                                                                 dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 16, 16, 124)  496         concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 16, 16, 124)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 16, 16, 48)   5952        activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 16, 16, 48)   192         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 16, 16, 48)   0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 16, 16, 12)   5184        activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 16, 16, 12)   0           conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 16, 16, 136)  0           concatenate_16[0][0]             \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 16, 16, 136)  544         concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 16, 16, 136)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 16, 16, 48)   6528        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 16, 16, 48)   192         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 16, 16, 48)   0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 16, 16, 12)   5184        activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 16, 16, 12)   0           conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 16, 16, 148)  0           concatenate_17[0][0]             \n",
            "                                                                 dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 16, 16, 148)  592         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 16, 16, 148)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 16, 16, 48)   7104        activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 16, 16, 48)   192         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 16, 16, 48)   0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 16, 16, 12)   5184        activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 16, 16, 12)   0           conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 16, 16, 160)  0           concatenate_18[0][0]             \n",
            "                                                                 dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 16, 16, 160)  640         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 16, 16, 160)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 16, 16, 48)   7680        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 16, 16, 48)   192         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 16, 16, 48)   0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 16, 16, 12)   5184        activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 16, 16, 12)   0           conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 16, 16, 172)  0           concatenate_19[0][0]             \n",
            "                                                                 dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 16, 16, 172)  688         concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 16, 16, 172)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 16, 16, 48)   8256        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 16, 16, 48)   192         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 16, 16, 48)   0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 16, 16, 12)   5184        activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 16, 16, 12)   0           conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 16, 16, 184)  0           concatenate_20[0][0]             \n",
            "                                                                 dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 16, 16, 184)  736         concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 16, 16, 184)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 16, 16, 48)   8832        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 16, 16, 48)   192         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 16, 16, 48)   0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 16, 16, 12)   5184        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 16, 16, 12)   0           conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 16, 16, 196)  0           concatenate_21[0][0]             \n",
            "                                                                 dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 16, 16, 196)  784         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 16, 16, 196)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 16, 16, 48)   9408        activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 16, 16, 48)   192         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 16, 16, 48)   0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 16, 16, 12)   5184        activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 16, 16, 12)   0           conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 16, 16, 208)  0           concatenate_22[0][0]             \n",
            "                                                                 dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 16, 16, 208)  832         concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 16, 16, 208)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 16, 16, 48)   9984        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 16, 16, 48)   192         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 16, 16, 48)   0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 16, 16, 12)   5184        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 16, 16, 12)   0           conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 16, 16, 220)  0           concatenate_23[0][0]             \n",
            "                                                                 dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 16, 16, 220)  880         concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 16, 16, 220)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 16, 16, 48)   10560       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 16, 16, 48)   192         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 16, 16, 48)   0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 16, 16, 12)   5184        activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 16, 16, 12)   0           conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 16, 16, 232)  0           concatenate_24[0][0]             \n",
            "                                                                 dropout_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 16, 16, 232)  928         concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 16, 16, 232)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 16, 16, 48)   11136       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 16, 16, 48)   192         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 16, 16, 48)   0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 16, 16, 12)   5184        activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 16, 16, 12)   0           conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 16, 16, 244)  0           concatenate_25[0][0]             \n",
            "                                                                 dropout_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 16, 16, 244)  976         concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 16, 16, 244)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 16, 16, 48)   11712       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 16, 16, 48)   192         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 16, 16, 48)   0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 16, 16, 12)   5184        activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_28 (Dropout)            (None, 16, 16, 12)   0           conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 16, 16, 256)  0           concatenate_26[0][0]             \n",
            "                                                                 dropout_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 16, 16, 256)  1024        concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 16, 16, 256)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 16, 16, 48)   12288       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 16, 16, 48)   192         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 16, 16, 48)   0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 16, 16, 12)   5184        activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_29 (Dropout)            (None, 16, 16, 12)   0           conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 16, 16, 268)  0           concatenate_27[0][0]             \n",
            "                                                                 dropout_29[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 16, 16, 268)  1072        concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 16, 16, 268)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 16, 16, 48)   12864       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 16, 16, 48)   192         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 16, 16, 48)   0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 16, 16, 12)   5184        activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 16, 16, 12)   0           conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 16, 16, 280)  0           concatenate_28[0][0]             \n",
            "                                                                 dropout_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 16, 16, 280)  1120        concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 16, 16, 280)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 16, 16, 48)   13440       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 16, 16, 48)   192         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 16, 16, 48)   0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 16, 16, 12)   5184        activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_31 (Dropout)            (None, 16, 16, 12)   0           conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 16, 16, 292)  0           concatenate_29[0][0]             \n",
            "                                                                 dropout_31[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 16, 16, 292)  1168        concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 16, 16, 292)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 16, 16, 48)   14016       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 16, 16, 48)   192         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 16, 16, 48)   0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 16, 16, 12)   5184        activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_32 (Dropout)            (None, 16, 16, 12)   0           conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 16, 16, 304)  0           concatenate_30[0][0]             \n",
            "                                                                 dropout_32[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 16, 16, 304)  1216        concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 16, 16, 304)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 16, 16, 208)  63232       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_33 (Dropout)            (None, 16, 16, 208)  0           conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 8, 8, 208)    0           dropout_33[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 8, 8, 208)    832         average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 8, 8, 208)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 8, 8, 48)     9984        activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 8, 8, 48)     192         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 8, 8, 48)     0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 8, 8, 12)     5184        activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_34 (Dropout)            (None, 8, 8, 12)     0           conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 8, 8, 220)    0           average_pooling2d_1[0][0]        \n",
            "                                                                 dropout_34[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 8, 8, 220)    880         concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 8, 8, 220)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 8, 8, 48)     10560       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 8, 8, 48)     192         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 8, 8, 48)     0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 8, 8, 12)     5184        activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_35 (Dropout)            (None, 8, 8, 12)     0           conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 8, 8, 232)    0           concatenate_32[0][0]             \n",
            "                                                                 dropout_35[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 8, 8, 232)    928         concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 8, 8, 232)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 48)     11136       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 48)     192         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 48)     0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 8, 8, 12)     5184        activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_36 (Dropout)            (None, 8, 8, 12)     0           conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 8, 8, 244)    0           concatenate_33[0][0]             \n",
            "                                                                 dropout_36[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 8, 8, 244)    976         concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 8, 8, 244)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 8, 8, 48)     11712       activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 8, 8, 48)     192         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 8, 8, 48)     0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 8, 8, 12)     5184        activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 8, 8, 12)     0           conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 8, 8, 256)    0           concatenate_34[0][0]             \n",
            "                                                                 dropout_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 8, 8, 256)    1024        concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 8, 8, 256)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 48)     12288       activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 8, 8, 48)     192         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 48)     0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 12)     5184        activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_38 (Dropout)            (None, 8, 8, 12)     0           conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 8, 8, 268)    0           concatenate_35[0][0]             \n",
            "                                                                 dropout_38[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 268)    1072        concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 268)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 48)     12864       activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 48)     192         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 48)     0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 12)     5184        activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_39 (Dropout)            (None, 8, 8, 12)     0           conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 8, 8, 280)    0           concatenate_36[0][0]             \n",
            "                                                                 dropout_39[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 280)    1120        concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 280)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 48)     13440       activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 48)     192         conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 48)     0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 12)     5184        activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_40 (Dropout)            (None, 8, 8, 12)     0           conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 8, 8, 292)    0           concatenate_37[0][0]             \n",
            "                                                                 dropout_40[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 292)    1168        concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 292)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 48)     14016       activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 48)     192         conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 48)     0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 12)     5184        activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_41 (Dropout)            (None, 8, 8, 12)     0           conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 8, 8, 304)    0           concatenate_38[0][0]             \n",
            "                                                                 dropout_41[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 304)    1216        concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 304)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 48)     14592       activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 48)     192         conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 48)     0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 12)     5184        activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_42 (Dropout)            (None, 8, 8, 12)     0           conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 8, 8, 316)    0           concatenate_39[0][0]             \n",
            "                                                                 dropout_42[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 316)    1264        concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 316)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 48)     15168       activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 48)     192         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 48)     0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 12)     5184        activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_43 (Dropout)            (None, 8, 8, 12)     0           conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 8, 8, 328)    0           concatenate_40[0][0]             \n",
            "                                                                 dropout_43[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 328)    1312        concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 328)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 48)     15744       activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 48)     192         conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 48)     0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 12)     5184        activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_44 (Dropout)            (None, 8, 8, 12)     0           conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 8, 8, 340)    0           concatenate_41[0][0]             \n",
            "                                                                 dropout_44[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 340)    1360        concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 340)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 48)     16320       activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 48)     192         conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 48)     0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 12)     5184        activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_45 (Dropout)            (None, 8, 8, 12)     0           conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 8, 8, 352)    0           concatenate_42[0][0]             \n",
            "                                                                 dropout_45[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 352)    1408        concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 352)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 48)     16896       activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 48)     192         conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 48)     0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 12)     5184        activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_46 (Dropout)            (None, 8, 8, 12)     0           conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 8, 8, 364)    0           concatenate_43[0][0]             \n",
            "                                                                 dropout_46[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 364)    1456        concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 364)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 48)     17472       activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 48)     192         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 48)     0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 8, 8, 12)     5184        activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_47 (Dropout)            (None, 8, 8, 12)     0           conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 8, 8, 376)    0           concatenate_44[0][0]             \n",
            "                                                                 dropout_47[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 8, 8, 376)    1504        concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 8, 8, 376)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 8, 8, 48)     18048       activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 8, 8, 48)     192         conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 8, 8, 48)     0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 8, 8, 12)     5184        activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_48 (Dropout)            (None, 8, 8, 12)     0           conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 8, 8, 388)    0           concatenate_45[0][0]             \n",
            "                                                                 dropout_48[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 8, 8, 388)    1552        concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 8, 8, 388)    0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 8, 8, 48)     18624       activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 8, 8, 48)     192         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 8, 8, 48)     0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 8, 8, 12)     5184        activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_49 (Dropout)            (None, 8, 8, 12)     0           conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 8, 8, 400)    0           concatenate_46[0][0]             \n",
            "                                                                 dropout_49[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 8, 8, 400)    1600        concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 8, 8, 400)    0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 400)          0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           4010        global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 872,458\n",
            "Trainable params: 846,090\n",
            "Non-trainable params: 26,368\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IeZElodLEG45",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "\t\t\tfeaturewise_center=False,  # set input mean to 0 over the dataset\n",
        "\t\t\tsamplewise_center=False,  # set each sample mean to 0\n",
        "\t\t\tfeaturewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "\t\t\tsamplewise_std_normalization=False,  # divide each input by its std\n",
        "\t\t\tzca_whitening=False,  # apply ZCA whitening\n",
        "\t\t\trotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "\t\t\twidth_shift_range=0.16,  # randomly shift images horizontally (fraction of total width)\n",
        "\t\t\theight_shift_range=0.16,  # randomly shift images vertically (fraction of total height)\n",
        "\t\t\thorizontal_flip=True,  # randomly flip images\n",
        "\t\t\tvertical_flip=False) # randomly flip images\n",
        "       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l0CI3oZKvqyQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def step_decay(epoch):\n",
        "\tinitial_lrate = 0.1\n",
        "\tlrate = 0.1\n",
        "\tif epoch >= 125 and epoch < 187:\n",
        "\t\tlrate = initial_lrate / 10\n",
        "\tif epoch >= 187 :\n",
        "\t\tlrate = initial_lrate / 100\n",
        "\t\n",
        "\treturn float(lrate)\n",
        "lrschedular = LearningRateScheduler(step_decay)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "b4XOsW3ahSkL",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer=Adam(),\n",
        "#               metrics=['accuracy'])\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(lr=0.1,momentum=0.9,nesterov=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "w5oLYwEMqK79",
        "outputId": "ed90baf7-45ae-4d02-896d-9087e69009a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "cell_type": "code",
      "source": [
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(model,\n",
        "                                              strategy = tf.contrib.tpu.TPUDistributionStrategy(\n",
        "                                                  tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://'+os.environ['COLAB_TPU_ADDR'])\n",
        "                                              )\n",
        "                                             )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (b'grpc://10.89.87.186:8470') for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 8983147937132826590)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 11067988314755813392)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 3553232749503011065)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 8860226884709928202)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 9600603507261866485)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 12890441708168868743)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 5167875681741854601)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 8072679836964091216)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 16253101541320373287)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6338233791557415909)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 10558966530293087597)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2484708679624374553)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.10000000149011612, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': True}\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.10000000149011612, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': True}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "crhGk7kEhXAz",
        "outputId": "0bddc724-2b7d-4360-bdb2-4d1373d92c0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8860
        }
      },
      "cell_type": "code",
      "source": [
        "# tpu_model.fit(x_train, y_train,\n",
        "#                     batch_size=batch_size,\n",
        "#                     epochs=50,\n",
        "#                     verbose=1,\n",
        "#                     validation_data=(x_test, y_test))\n",
        "\n",
        "tpu_model.fit_generator(datagen.flow(x_train, y_train,\n",
        "\t\t\t\t\t\t\t\t\t batch_size=64),\n",
        "\t\t\t\t\t\tsteps_per_epoch=782,epochs=250,verbose=1,callbacks=[lrschedular])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(8,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(8, 32, 32, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(8, 10), dtype=tf.float32, name='dense_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.10000000149011612, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': True}\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.SGD object at 0x7fa9406e5ef0> []\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 88.06197094917297 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "INFO:tensorflow:CPU -> TPU lr: 0.10000000149011612 {0.1}\n",
            "INFO:tensorflow:CPU -> TPU momentum: 0.8999999761581421 {0.9}\n",
            "INFO:tensorflow:CPU -> TPU decay: 0.0 {0.0}\n",
            "WARNING:tensorflow:Cannot update non-variable config: nesterov\n",
            "289/782 [==========>...................] - ETA: 7:04 - loss: 3.7213 - acc: 0.3159INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(2,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(2, 32, 32, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(2, 10), dtype=tf.float32, name='dense_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.SGD object at 0x7fa9406e5ef0> [<tf.Variable 'tpu_140365009824288/SGD/iterations:0' shape=() dtype=int64>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92574f160>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92574f630>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92574f7f0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92574fe10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9256a8fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa925676d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa925619f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa925605c88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9255cee48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa925573d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9254e17b8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9254a9f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9254d0e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92543e518>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa925409d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9253a9cc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa925318c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9252e2f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9252ad2b0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92521b780>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9252414a8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa925208e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa925176f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92511b198>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9250e44a8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9250d0f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa925078f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92503fef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924fadcf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924f75da0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924f1feb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924f0acc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924e52f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924e78e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924de8cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924db1ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924d55f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924d40dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924d09da0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924cb0c88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924c1df28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924be7fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924c0cda0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924b7dc18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924b46cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924aebcf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924a55be0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924a1ff28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9249e8240>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924958e80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92497bd30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924947b70>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9248b2f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92485a128>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924823940>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92480deb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9247b4f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92477fe80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9246ebc88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9246b7f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92465bc18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924646e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92460eeb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9245b7da0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924526f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9244edac8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924511f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92447fd68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924448d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9243f0c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92435acf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924323cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924349da0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9242bbbe0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924281d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924227c88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9242105c0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92415ceb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92412b1d0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9240eff60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9240b8f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa924081b00>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923feebe0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923f949b0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923f61f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923f4afd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923ef4d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923ebae10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923e2bc18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923df2f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923d98e80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923d81da0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923d4de48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923cf1d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923c61c50>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923c28f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923c4eeb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923bb8cc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923b83fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923b2df98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923a95cc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923a60e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923a86d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9239f5780>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9239c0fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923962e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9238d5550>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92389ce48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9238bd470>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92382cef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9237f5fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9237bea90>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92372ed30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9236d44e0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92369de80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923689fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92362dc88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9235f7da0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923565ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92352ec50>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9234d4f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9234c1d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923488dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923432ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92339dcf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923367eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92338ce48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9232f7d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9232c3d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923269fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9231d3e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92319fdd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9231c3cc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa923131f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9230faf60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92309fdd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92308f518>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922fdbd30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922ffd400>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922f67be0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922f32f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922efc278>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922e6c748>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922e8eb70>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922dd9e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922dc7f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922d6a160>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922d35fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922ca3ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922cc9f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922c91eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922bfdfd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922bcac88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922b6fa20>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922adbe48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922aa3ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922acadd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922a38c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922a03eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9229a6f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922913d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9228dcd68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922901c50>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922870d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922839d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9227dddd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9227cebe0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922716fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92273ccc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9226a75f8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92266fef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92263c208>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9225a7a90>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9225cefd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922517b38>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922505ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9224aa0f0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922474908>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9223e1e80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922407d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9223d0e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92233ff28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922308c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9222abeb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922218dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9221e2e80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922206d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922175ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92213fd68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9220e3ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9220cfd30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92201bcf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa922044fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921faecf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921f77cc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921f1cd68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921f0d7b8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921e56d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921e78e80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921de55c0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921db3e80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921d53b38>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921d43ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921d09f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921c55ac8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921c46d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921be9cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921bb3eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921b1efd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921b44cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921b0bdd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921a7ef60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921a43ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9219e9e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921958d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921922e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921947cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9218b4d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92187eef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92181fe80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92180efd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92175ad68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921781f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9216ebe10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9216b6e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921659cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92164bf60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921611f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9215b6e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921525518>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9214f1d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921510cc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92147ec18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92144bf98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9213932b0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921382780>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9213284a8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9212f0e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92125ef98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921283198>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92124b4a8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9211b9f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92115ef28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921128ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921094cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92105fda0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa921086eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920ff3cc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920fbaf28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920f62e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920f4fcf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920e99ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920ebaf98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920e2bdd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920df1da0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920d98c88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920d87f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920d51fd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920cf4da0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920c67c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920c2dcf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920bd3cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920bbdbe0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920b89f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920b50240>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920ac1e80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920a64d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920a2fb70>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92099af28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9209c4128>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92098a940>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9208f8eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92089bf28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920868e80>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9207d5c88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9207a1f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9207c5c18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92072de10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9206fbeb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9206a0da0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92068ef60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9205d6ac8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9205faf28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920569d68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920531d30>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9204dac18>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9204c5cf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92048dcf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920433da0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9203a2be0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92036cd68>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa920391c88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9202fb5c0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9202c6eb8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9202151d0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9201daf60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa9201a4f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92016ab00>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7fa92018fb70>]\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 94.02774095535278 secs\n",
            "782/782 [==============================] - 416s 532ms/step - loss: 3.3304 - acc: 0.4094\n",
            "Epoch 2/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 2.5178 - acc: 0.5735\n",
            "Epoch 3/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 2.0535 - acc: 0.6414\n",
            "Epoch 4/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 1.7315 - acc: 0.6881\n",
            "Epoch 5/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 1.5096 - acc: 0.7181\n",
            "Epoch 6/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 1.3550 - acc: 0.7375\n",
            "Epoch 7/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 1.2479 - acc: 0.7518\n",
            "Epoch 8/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 1.1708 - acc: 0.7593\n",
            "Epoch 9/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 1.1129 - acc: 0.7690\n",
            "Epoch 10/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 1.0758 - acc: 0.7752\n",
            "Epoch 11/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 1.0458 - acc: 0.7792\n",
            "Epoch 12/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 1.0294 - acc: 0.7808\n",
            "Epoch 13/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 1.0071 - acc: 0.7864\n",
            "Epoch 14/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 1.0028 - acc: 0.7875\n",
            "Epoch 15/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.9932 - acc: 0.7908\n",
            "Epoch 16/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.9825 - acc: 0.7934\n",
            "Epoch 17/250\n",
            "782/782 [==============================] - 53s 67ms/step - loss: 0.9756 - acc: 0.7961\n",
            "Epoch 18/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9695 - acc: 0.7978\n",
            "Epoch 19/250\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 0.9630 - acc: 0.8012\n",
            "Epoch 20/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9629 - acc: 0.8005\n",
            "Epoch 21/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9596 - acc: 0.8022\n",
            "Epoch 22/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9522 - acc: 0.8061\n",
            "Epoch 23/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9462 - acc: 0.8082\n",
            "Epoch 24/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.9502 - acc: 0.8055\n",
            "Epoch 25/250\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 0.9410 - acc: 0.8103\n",
            "Epoch 26/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.9370 - acc: 0.8119\n",
            "Epoch 27/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9415 - acc: 0.8132\n",
            "Epoch 28/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9294 - acc: 0.8158\n",
            "Epoch 29/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.9343 - acc: 0.8139\n",
            "Epoch 30/250\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 0.9335 - acc: 0.8150\n",
            "Epoch 31/250\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 0.9248 - acc: 0.8178\n",
            "Epoch 32/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9269 - acc: 0.8164\n",
            "Epoch 33/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9254 - acc: 0.8170\n",
            "Epoch 34/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9232 - acc: 0.8187\n",
            "Epoch 35/250\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 0.9215 - acc: 0.8194\n",
            "Epoch 36/250\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 0.9210 - acc: 0.8197\n",
            "Epoch 37/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9191 - acc: 0.8221\n",
            "Epoch 38/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9242 - acc: 0.8183\n",
            "Epoch 39/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.9154 - acc: 0.8225\n",
            "Epoch 40/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9216 - acc: 0.8184\n",
            "Epoch 41/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.9125 - acc: 0.8236\n",
            "Epoch 42/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9118 - acc: 0.8233\n",
            "Epoch 43/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.9159 - acc: 0.8209\n",
            "Epoch 44/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9106 - acc: 0.8258\n",
            "Epoch 45/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9119 - acc: 0.8238\n",
            "Epoch 46/250\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 0.9057 - acc: 0.8253\n",
            "Epoch 47/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9090 - acc: 0.8256\n",
            "Epoch 48/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9097 - acc: 0.8254\n",
            "Epoch 49/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9049 - acc: 0.8278\n",
            "Epoch 50/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9025 - acc: 0.8282\n",
            "Epoch 51/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9044 - acc: 0.8281\n",
            "Epoch 52/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9045 - acc: 0.8271\n",
            "Epoch 53/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.9094 - acc: 0.8252\n",
            "Epoch 54/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9003 - acc: 0.8285\n",
            "Epoch 55/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9005 - acc: 0.8292\n",
            "Epoch 56/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.8984 - acc: 0.8287\n",
            "Epoch 57/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9021 - acc: 0.8283\n",
            "Epoch 58/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9058 - acc: 0.8272\n",
            "Epoch 59/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.9043 - acc: 0.8295\n",
            "Epoch 60/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9021 - acc: 0.8290\n",
            "Epoch 61/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8973 - acc: 0.8302\n",
            "Epoch 62/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9015 - acc: 0.8309\n",
            "Epoch 63/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8959 - acc: 0.8305\n",
            "Epoch 64/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9035 - acc: 0.8291\n",
            "Epoch 65/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8969 - acc: 0.8309\n",
            "Epoch 66/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8966 - acc: 0.8296\n",
            "Epoch 67/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9014 - acc: 0.8297\n",
            "Epoch 68/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9017 - acc: 0.8300\n",
            "Epoch 69/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.9002 - acc: 0.8314\n",
            "Epoch 70/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8897 - acc: 0.8337\n",
            "Epoch 71/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.9031 - acc: 0.8291\n",
            "Epoch 72/250\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 0.8930 - acc: 0.8329\n",
            "Epoch 73/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.8907 - acc: 0.8327\n",
            "Epoch 74/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8937 - acc: 0.8345\n",
            "Epoch 75/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8905 - acc: 0.8330\n",
            "Epoch 76/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.8947 - acc: 0.8331\n",
            "Epoch 77/250\n",
            "782/782 [==============================] - 53s 67ms/step - loss: 0.8959 - acc: 0.8328\n",
            "Epoch 78/250\n",
            "782/782 [==============================] - 53s 67ms/step - loss: 0.8956 - acc: 0.8341\n",
            "Epoch 79/250\n",
            "782/782 [==============================] - 53s 67ms/step - loss: 0.8900 - acc: 0.8344\n",
            "Epoch 80/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.8938 - acc: 0.8323\n",
            "Epoch 81/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.8948 - acc: 0.8327\n",
            "Epoch 82/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8919 - acc: 0.8337\n",
            "Epoch 83/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8921 - acc: 0.8345\n",
            "Epoch 84/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8917 - acc: 0.8349\n",
            "Epoch 85/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.8948 - acc: 0.8320\n",
            "Epoch 86/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.9005 - acc: 0.8309\n",
            "Epoch 87/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.8908 - acc: 0.8354\n",
            "Epoch 88/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8888 - acc: 0.8350\n",
            "Epoch 89/250\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 0.8886 - acc: 0.8362\n",
            "Epoch 90/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8933 - acc: 0.8329\n",
            "Epoch 91/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8883 - acc: 0.8357\n",
            "Epoch 92/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.8900 - acc: 0.8362\n",
            "Epoch 93/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.8908 - acc: 0.8352\n",
            "Epoch 94/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8873 - acc: 0.8365\n",
            "Epoch 95/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8871 - acc: 0.8339\n",
            "Epoch 96/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8940 - acc: 0.8340\n",
            "Epoch 97/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8920 - acc: 0.8317\n",
            "Epoch 98/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8928 - acc: 0.8360\n",
            "Epoch 99/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.8899 - acc: 0.8351\n",
            "Epoch 100/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.8892 - acc: 0.8343\n",
            "Epoch 101/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8935 - acc: 0.8345\n",
            "Epoch 102/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8817 - acc: 0.8381\n",
            "Epoch 103/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8888 - acc: 0.8341\n",
            "Epoch 104/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8881 - acc: 0.8357\n",
            "Epoch 105/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8851 - acc: 0.8349\n",
            "Epoch 106/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8847 - acc: 0.8356\n",
            "Epoch 107/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8863 - acc: 0.8362\n",
            "Epoch 108/250\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 0.8886 - acc: 0.8350\n",
            "Epoch 109/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.8891 - acc: 0.8345\n",
            "Epoch 110/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8873 - acc: 0.8363\n",
            "Epoch 111/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8854 - acc: 0.8369\n",
            "Epoch 112/250\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 0.8883 - acc: 0.8361\n",
            "Epoch 113/250\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 0.8894 - acc: 0.8364\n",
            "Epoch 114/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8876 - acc: 0.8370\n",
            "Epoch 115/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8851 - acc: 0.8376\n",
            "Epoch 116/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.8849 - acc: 0.8368\n",
            "Epoch 117/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.8856 - acc: 0.8358\n",
            "Epoch 118/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8839 - acc: 0.8370\n",
            "Epoch 119/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8849 - acc: 0.8350\n",
            "Epoch 120/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8835 - acc: 0.8362\n",
            "Epoch 121/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.8844 - acc: 0.8367\n",
            "Epoch 122/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.8834 - acc: 0.8351\n",
            "Epoch 123/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.8850 - acc: 0.8370\n",
            "Epoch 124/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8771 - acc: 0.8388\n",
            "Epoch 125/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.8912 - acc: 0.8318\n",
            "Epoch 126/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.7473 - acc: 0.8834\n",
            "Epoch 127/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.6847 - acc: 0.9019\n",
            "Epoch 128/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.6555 - acc: 0.9086\n",
            "Epoch 129/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.6328 - acc: 0.9130\n",
            "Epoch 130/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.6180 - acc: 0.9148\n",
            "Epoch 131/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.6026 - acc: 0.9172\n",
            "Epoch 132/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.5865 - acc: 0.9205\n",
            "Epoch 133/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.5745 - acc: 0.9198\n",
            "Epoch 134/250\n",
            "782/782 [==============================] - 55s 71ms/step - loss: 0.5625 - acc: 0.9202\n",
            "Epoch 135/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.5563 - acc: 0.9219\n",
            "Epoch 136/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.5411 - acc: 0.9240\n",
            "Epoch 137/250\n",
            "782/782 [==============================] - 58s 75ms/step - loss: 0.5300 - acc: 0.9257\n",
            "Epoch 138/250\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 0.5247 - acc: 0.9256\n",
            "Epoch 139/250\n",
            "782/782 [==============================] - 55s 71ms/step - loss: 0.5191 - acc: 0.9245\n",
            "Epoch 140/250\n",
            "782/782 [==============================] - 56s 71ms/step - loss: 0.5042 - acc: 0.9286\n",
            "Epoch 141/250\n",
            "782/782 [==============================] - 55s 71ms/step - loss: 0.4983 - acc: 0.9277\n",
            "Epoch 142/250\n",
            "782/782 [==============================] - 56s 72ms/step - loss: 0.4864 - acc: 0.9300\n",
            "Epoch 143/250\n",
            "782/782 [==============================] - 56s 72ms/step - loss: 0.4839 - acc: 0.9285\n",
            "Epoch 144/250\n",
            "782/782 [==============================] - 56s 71ms/step - loss: 0.4781 - acc: 0.9297\n",
            "Epoch 145/250\n",
            "782/782 [==============================] - 55s 71ms/step - loss: 0.4733 - acc: 0.9288\n",
            "Epoch 146/250\n",
            "782/782 [==============================] - 56s 72ms/step - loss: 0.4657 - acc: 0.9314\n",
            "Epoch 147/250\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 0.4638 - acc: 0.9300\n",
            "Epoch 148/250\n",
            "782/782 [==============================] - 56s 71ms/step - loss: 0.4555 - acc: 0.9307\n",
            "Epoch 149/250\n",
            "782/782 [==============================] - 55s 71ms/step - loss: 0.4549 - acc: 0.9302\n",
            "Epoch 150/250\n",
            "782/782 [==============================] - 55s 71ms/step - loss: 0.4473 - acc: 0.9316\n",
            "Epoch 151/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4432 - acc: 0.9326\n",
            "Epoch 152/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4378 - acc: 0.9327\n",
            "Epoch 153/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4365 - acc: 0.9321\n",
            "Epoch 154/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4366 - acc: 0.9299\n",
            "Epoch 155/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4292 - acc: 0.9327\n",
            "Epoch 156/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4310 - acc: 0.9306\n",
            "Epoch 157/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4259 - acc: 0.9316\n",
            "Epoch 158/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4241 - acc: 0.9306\n",
            "Epoch 159/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4246 - acc: 0.9305\n",
            "Epoch 160/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4208 - acc: 0.9317\n",
            "Epoch 161/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4169 - acc: 0.9330\n",
            "Epoch 162/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4152 - acc: 0.9318\n",
            "Epoch 163/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4185 - acc: 0.9303\n",
            "Epoch 164/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4148 - acc: 0.9306\n",
            "Epoch 165/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4076 - acc: 0.9328\n",
            "Epoch 166/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4071 - acc: 0.9327\n",
            "Epoch 167/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4065 - acc: 0.9333\n",
            "Epoch 168/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4087 - acc: 0.9315\n",
            "Epoch 169/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4070 - acc: 0.9324\n",
            "Epoch 170/250\n",
            "782/782 [==============================] - 55s 71ms/step - loss: 0.4062 - acc: 0.9322\n",
            "Epoch 171/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4038 - acc: 0.9312\n",
            "Epoch 172/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4004 - acc: 0.9329\n",
            "Epoch 173/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3972 - acc: 0.9339\n",
            "Epoch 174/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3973 - acc: 0.9338\n",
            "Epoch 175/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3986 - acc: 0.9318\n",
            "Epoch 176/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.4006 - acc: 0.9313\n",
            "Epoch 177/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3979 - acc: 0.9334\n",
            "Epoch 178/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3969 - acc: 0.9340\n",
            "Epoch 179/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3987 - acc: 0.9320\n",
            "Epoch 180/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3969 - acc: 0.9323\n",
            "Epoch 181/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3996 - acc: 0.9320\n",
            "Epoch 182/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3964 - acc: 0.9330\n",
            "Epoch 183/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3961 - acc: 0.9313\n",
            "Epoch 184/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3928 - acc: 0.9346\n",
            "Epoch 185/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3931 - acc: 0.9323\n",
            "Epoch 186/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3965 - acc: 0.9314\n",
            "Epoch 187/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3910 - acc: 0.9331\n",
            "Epoch 188/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3492 - acc: 0.9486\n",
            "Epoch 189/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3270 - acc: 0.9566\n",
            "Epoch 190/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3186 - acc: 0.9590\n",
            "Epoch 191/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3141 - acc: 0.9598\n",
            "Epoch 192/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.3131 - acc: 0.9609\n",
            "Epoch 193/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3101 - acc: 0.9614\n",
            "Epoch 194/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.3073 - acc: 0.9616\n",
            "Epoch 195/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3029 - acc: 0.9639\n",
            "Epoch 196/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3014 - acc: 0.9635\n",
            "Epoch 197/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3007 - acc: 0.9644\n",
            "Epoch 198/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.3004 - acc: 0.9644\n",
            "Epoch 199/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2957 - acc: 0.9666\n",
            "Epoch 200/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2942 - acc: 0.9664\n",
            "Epoch 201/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2929 - acc: 0.9662\n",
            "Epoch 202/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.2922 - acc: 0.9664\n",
            "Epoch 203/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2862 - acc: 0.9679\n",
            "Epoch 204/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2872 - acc: 0.9675\n",
            "Epoch 205/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2867 - acc: 0.9676\n",
            "Epoch 206/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2856 - acc: 0.9684\n",
            "Epoch 207/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.2836 - acc: 0.9686\n",
            "Epoch 208/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.2797 - acc: 0.9694\n",
            "Epoch 209/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.2808 - acc: 0.9690\n",
            "Epoch 210/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2788 - acc: 0.9704\n",
            "Epoch 211/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2779 - acc: 0.9695\n",
            "Epoch 212/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2783 - acc: 0.9695\n",
            "Epoch 213/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.2745 - acc: 0.9707\n",
            "Epoch 214/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.2776 - acc: 0.9698\n",
            "Epoch 215/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2736 - acc: 0.9715\n",
            "Epoch 216/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2724 - acc: 0.9707\n",
            "Epoch 217/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2735 - acc: 0.9696\n",
            "Epoch 218/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2705 - acc: 0.9716\n",
            "Epoch 219/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.2687 - acc: 0.9717\n",
            "Epoch 220/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2673 - acc: 0.9726\n",
            "Epoch 221/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.2692 - acc: 0.9719\n",
            "Epoch 222/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2669 - acc: 0.9718\n",
            "Epoch 223/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2660 - acc: 0.9720\n",
            "Epoch 224/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2652 - acc: 0.9725\n",
            "Epoch 225/250\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.2651 - acc: 0.9723\n",
            "Epoch 226/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2644 - acc: 0.9727\n",
            "Epoch 227/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.2630 - acc: 0.9724\n",
            "Epoch 228/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2639 - acc: 0.9728\n",
            "Epoch 229/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2609 - acc: 0.9738\n",
            "Epoch 230/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2612 - acc: 0.9729\n",
            "Epoch 231/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2592 - acc: 0.9734\n",
            "Epoch 232/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2593 - acc: 0.9733\n",
            "Epoch 233/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2582 - acc: 0.9735\n",
            "Epoch 234/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2582 - acc: 0.9732\n",
            "Epoch 235/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2562 - acc: 0.9731\n",
            "Epoch 236/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2576 - acc: 0.9734\n",
            "Epoch 237/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2570 - acc: 0.9738\n",
            "Epoch 238/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2546 - acc: 0.9743\n",
            "Epoch 239/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2526 - acc: 0.9746\n",
            "Epoch 240/250\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.2558 - acc: 0.9733\n",
            "Epoch 241/250\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.2518 - acc: 0.9745\n",
            "Epoch 242/250\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2498 - acc: 0.9746\n",
            "Epoch 243/250\n",
            "782/782 [==============================] - 55s 71ms/step - loss: 0.2520 - acc: 0.9740\n",
            "Epoch 244/250\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 0.2513 - acc: 0.9744\n",
            "Epoch 245/250\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 0.2491 - acc: 0.9756\n",
            "Epoch 246/250\n",
            "782/782 [==============================] - 55s 71ms/step - loss: 0.2478 - acc: 0.9759\n",
            "Epoch 247/250\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 0.2478 - acc: 0.9754\n",
            "Epoch 248/250\n",
            "782/782 [==============================] - 55s 71ms/step - loss: 0.2472 - acc: 0.9748\n",
            "Epoch 249/250\n",
            "782/782 [==============================] - 55s 71ms/step - loss: 0.2445 - acc: 0.9757\n",
            "Epoch 250/250\n",
            "782/782 [==============================] - 55s 71ms/step - loss: 0.2457 - acc: 0.9760\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa95430f1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZcWydmIVhZGr",
        "outputId": "df35a837-9db6-4744-8b46-43dc319ea286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = tpu_model.evaluate(x_test, y_test, verbose=1)\n",
        "print(score)\n",
        "print('Test loss: %.3f ' % (score[0]))\n",
        "print('Test accuracy: %.3f ' % (score[1]*100))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(4,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(4, 32, 32, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(4, 10), dtype=tf.float32, name='dense_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.10000000149011612, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': True}\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.SGD object at 0x7fa93f6a8780> []\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 69.7616708278656 secs\n",
            " 9984/10000 [============================>.] - ETA: 0sINFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(2,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(2, 32, 32, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(2, 10), dtype=tf.float32, name='dense_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.SGD object at 0x7fa93f6a8780> []\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 43.13383769989014 secs\n",
            "10000/10000 [==============================] - 182s 18ms/step\n",
            "[0.36509302864074705, 0.9458]\n",
            "Test loss: 0.365 \n",
            "Test accuracy: 94.580 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UE3lF6EH1r_L",
        "outputId": "5afcc4f3-8084-4ada-9a22-4015958f318c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "tpu_model.save_weights(\"DNST_weights_Shravan_B9_change_mean_std.h5\")\n",
        "tpu_model.save(\"DNST_model_Shravan_B9_change_mean_std.hdf5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU momentum: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU nesterov: True\n",
            "WARNING:tensorflow:Cannot update non-variable config: nesterov\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU momentum: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU nesterov: True\n",
            "WARNING:tensorflow:Cannot update non-variable config: nesterov\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Og56VCRh5j8V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VmSIqsez3C-o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Link for \n",
        "Weights:  https://drive.google.com/open?id=14lLLPW7OZtJ0flWSkMkoghfqxfzKxjGH \n",
        "Model:  https://drive.google.com/open?id=1RC4TCM72gSdoVNfjA63a_hcUG8IBpSZB\n",
        "\n",
        "\n",
        "# References\n",
        "1. Original Densenet Paper: https://arxiv.org/pdf/1608.06993\n",
        "2. https://medium.com/intuitionmachine/notes-on-the-implementation-densenet-in-tensorflow-beeda9dd1504\n",
        "3. https://forums.fast.ai/t/training-a-model-from-scratch-cifar-10/7897\n",
        "4. https://towardsdatascience.com/densenet-2810936aeebb\n",
        "5. https://towardsdatascience.com/normalized-direction-preserving-adam-switching-from-adam-to-sgd-and-nesterov-momentum-adam-with-460be5ddf686\n",
        "\n",
        "\n",
        "# Densenet implementations\n",
        "1. Original Densenet Implementation: https://github.com/liuzhuang13/DenseNet\n",
        "2. Fast.ai: http://files.fast.ai/part2/lesson13/densenet-keras.ipynb\n",
        "3. Github Users\n",
        "\ta. https://github.com/titu1994/DenseNet\n",
        "\tb. https://github.com/flyyufelix/DenseNet-Keras \n",
        "\n",
        "# LR Callbacks\n",
        "1. Cyclic Learning Rate: https://github.com/bckenstler/CLR\n",
        "2. SGDR: https://gist.github.com/t2kasa/490610116ddb0f3b664458d0e086e643\n",
        "3. SWATS: https://arxiv.org/pdf/1712.07628 (Implementation not found)\n",
        "\thttps://github.com/kweonwooj/papers/issues/76\n",
        "\thttps://www.groundai.com/project/improving-generalization-performance-by-switching-from-adam-to-sgd/\n",
        "\t"
      ]
    }
  ]
}